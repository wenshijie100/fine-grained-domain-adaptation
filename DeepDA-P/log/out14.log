nohup: ignoring input
lmmd 2022 77G own DAN/DAN.yaml
Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=30, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, momentum=0.9, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='77G', tgt_domain='own', tname='transfer', transfer_loss='lmmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
JUST DO IT
run my Parkinson code
transfer
TRAIN Length: 2593 255 TEST Length: 2804 565
DATA_PROFILE   train: 2593 train2: 2804 test: 2804
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f24f2ddb040> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f24ea9c7eb0> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f24ea9c7d60> False
CLASS: 4 565
LLL: {}
BOTTLENECK_LIST: [Linear(in_features=512, out_features=256, bias=True), ReLU()]
TYPE: {'loss_type': 'lmmd', 'max_iter': 20000, 'num_class': 4, 'my_person_item': <my_person_item.PersonItem object at 0x7f24eaa5f6d0>}
KWARGS {'my_person_item': <my_person_item.PersonItem object at 0x7f24eaa5f6d0>}
TransferNet(
  (base_network): ResNet(
    (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (4): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (5): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(256, 512, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (avgpool): AdaptiveAvgPool1d(output_size=1)
  )
  (bottleneck_layer): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): ReLU()
  )
  (classifier_layer): Linear(in_features=256, out_features=4, bias=True)
  (adapt_loss): TransferLoss(
    (loss_func): LMMDLoss()
  )
  (criterion): CrossEntropyLoss()
)
initial_lr 1.0
transfer_world
1.8.1+cu111
True
LEN: 0 0
LOADER: <data_loader.InfiniteDataLoader object at 0x7f24ea9c3c40> <data_loader.InfiniteDataLoader object at 0x7f24eaa089a0>
N: 100
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.29386590584878747 F1_MA: 0.34893005748189715
BEST_F1_MI: 0.29386590584878747 BEST_F1_MA: 0.34893005748189715
[[ 784 1818   33    9]
 [   0    6    8   40]
 [   0    0   13   68]
 [   0    1    3   21]]
Epoch: [ 1/200], cls_loss: 0.8191, transfer_loss: 0.0008, total_Loss: 0.8195
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.5477888730385164 F1_MA: 0.3151074820939084
BEST_F1_MI: 0.5477888730385164 BEST_F1_MA: 0.34893005748189715
[[1502  862  238   42]
 [   0    2   10   42]
 [   0    1   18   62]
 [   0    0   11   14]]
Epoch: [ 2/200], cls_loss: 0.6395, transfer_loss: 0.0023, total_Loss: 0.6407
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.7685449358059915 F1_MA: 0.339425275674084
BEST_F1_MI: 0.7685449358059915 BEST_F1_MA: 0.34893005748189715
[[2125  462   48    9]
 [   0    5   22   27]
 [   0    0   15   66]
 [   0    2   13   10]]
Epoch: [ 3/200], cls_loss: 0.6249, transfer_loss: 0.0046, total_Loss: 0.6272
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9015691868758916 F1_MA: 0.4647949708147374
BEST_F1_MI: 0.9015691868758916 BEST_F1_MA: 0.4647949708147374
[[2470  170    4    0]
 [   1   29   17    7]
 [   0   29   22   30]
 [   0   11    7    7]]
Epoch: [ 4/200], cls_loss: 0.5464, transfer_loss: 0.0067, total_Loss: 0.5498
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.39087018544935814 F1_MA: 0.33143110535470965
BEST_F1_MI: 0.9015691868758916 BEST_F1_MA: 0.4647949708147374
[[1036 1237  365    6]
 [   0    4   37   13]
 [   0   13   48   20]
 [   0    3   14    8]]
Epoch: [ 5/200], cls_loss: 0.5285, transfer_loss: 0.0084, total_Loss: 0.5327
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9454350927246791 F1_MA: 0.5462270315824855
BEST_F1_MI: 0.9454350927246791 BEST_F1_MA: 0.5462270315824855
[[2605   39    0    0]
 [  13   37    1    3]
 [  22   54    2    3]
 [   2   16    0    7]]
Epoch: [ 6/200], cls_loss: 0.5157, transfer_loss: 0.0113, total_Loss: 0.5213
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.023537803138373753 F1_MA: 0.14319278546357253
BEST_F1_MI: 0.9454350927246791 BEST_F1_MA: 0.5462270315824855
[[   0    4 2640    0]
 [   0    3   44    7]
 [   0   11   57   13]
 [   0    2   17    6]]
Epoch: [ 7/200], cls_loss: 0.4776, transfer_loss: 0.0117, total_Loss: 0.4834
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.8965763195435092 F1_MA: 0.42232163658045546
BEST_F1_MI: 0.9454350927246791 BEST_F1_MA: 0.5462270315824855
[[2475  149    6   14]
 [   1   12   13   28]
 [   0   15   15   51]
 [   0    9    4   12]]
Epoch: [ 8/200], cls_loss: 0.4705, transfer_loss: 0.0148, total_Loss: 0.4779
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9186875891583453 F1_MA: 0.4619783339123039
BEST_F1_MI: 0.9454350927246791 BEST_F1_MA: 0.5462270315824855
[[2509  120   15    0]
 [   2    9   32   11]
 [   0   11   51   19]
 [   0    2   16    7]]
Epoch: [ 9/200], cls_loss: 0.4336, transfer_loss: 0.0177, total_Loss: 0.4425
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9539942938659058 F1_MA: 0.5463415669600552
BEST_F1_MI: 0.9539942938659058 BEST_F1_MA: 0.5463415669600552
[[2625   19    0    0]
 [   7   39    1    7]
 [   4   60    4   13]
 [   3   15    0    7]]
Epoch: [10/200], cls_loss: 0.4097, transfer_loss: 0.0166, total_Loss: 0.4180
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.023894436519258207 F1_MA: 0.15643356967181465
BEST_F1_MI: 0.9539942938659058 BEST_F1_MA: 0.5463415669600552
[[   0    3 2641    0]
 [   0    1   52    1]
 [   0   12   60    9]
 [   0    1   18    6]]
Epoch: [11/200], cls_loss: 0.3900, transfer_loss: 0.0137, total_Loss: 0.3968
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9350927246790299 F1_MA: 0.4444003621777549
BEST_F1_MI: 0.9539942938659058 BEST_F1_MA: 0.5463415669600552
[[2571   65    7    1]
 [   1   12   27   14]
 [   0   15   31   35]
 [   0    7   10    8]]
Epoch: [12/200], cls_loss: 0.3881, transfer_loss: 0.0171, total_Loss: 0.3966
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.025320970042796005 F1_MA: 0.28236057861465896
BEST_F1_MI: 0.9539942938659058 BEST_F1_MA: 0.5463415669600552
[[   1 2629   14    0]
 [   0    9   43    2]
 [   0   18   61    2]
 [   0   10   15    0]]
Epoch: [13/200], cls_loss: 0.3408, transfer_loss: 0.0157, total_Loss: 0.3486
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.7139800285306704 F1_MA: 0.3951945615314859
BEST_F1_MI: 0.9539942938659058 BEST_F1_MA: 0.5463415669600552
[[1951  692    0    1]
 [   0   36   12    6]
 [   0   62   14    5]
 [   0   17    7    1]]
Epoch: [14/200], cls_loss: 0.3329, transfer_loss: 0.0172, total_Loss: 0.3415
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9604136947218259 F1_MA: 0.5435610831682944
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2636    6    2    0]
 [  16   17   20    1]
 [  15   29   34    3]
 [   4   11    4    6]]
Epoch: [15/200], cls_loss: 0.3621, transfer_loss: 0.0155, total_Loss: 0.3699
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.8701854493580599 F1_MA: 0.42966636011736364
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2382  244   12    6]
 [   0    6   29   19]
 [   0   12   45   24]
 [   0    6   12    7]]
Epoch: [16/200], cls_loss: 0.2859, transfer_loss: 0.0176, total_Loss: 0.2947
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.015691868758915834 F1_MA: 0.21490187908932587
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[   0   19    4 2621]
 [   0    4    4   46]
 [   0   15   28   38]
 [   0   11    2   12]]
Epoch: [17/200], cls_loss: 0.3134, transfer_loss: 0.0167, total_Loss: 0.3217
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.025320970042796005 F1_MA: 0.39266251522019463
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[  14 2630    0    0]
 [   0   48    0    6]
 [   0   65    2   14]
 [   0   18    0    7]]
Epoch: [18/200], cls_loss: 0.3020, transfer_loss: 0.0179, total_Loss: 0.3109
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9572039942938659 F1_MA: 0.49669875164706206
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2628    9    7    0]
 [  15   14   19    6]
 [  10   19   35   17]
 [   0   13    5    7]]
Epoch: [19/200], cls_loss: 0.2953, transfer_loss: 0.0184, total_Loss: 0.3046
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.023181169757489302 F1_MA: 0.13515139420304575
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[   0    2 2642    0]
 [   0    0   52    2]
 [   0   12   58   11]
 [   0    5   13    7]]
Epoch: [20/200], cls_loss: 0.2620, transfer_loss: 0.0183, total_Loss: 0.2712
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.026390870185449358 F1_MA: 0.2523755655486124
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[   1    0 2643    0]
 [   0    1   53    0]
 [   0    8   72    1]
 [   0    0   25    0]]
Epoch: [21/200], cls_loss: 0.2784, transfer_loss: 0.0174, total_Loss: 0.2871
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9547075606276747 F1_MA: 0.5057139311045928
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2630   13    1    0]
 [  18   19    5   12]
 [   9   38   21   13]
 [   2   15    1    7]]
Epoch: [22/200], cls_loss: 0.2692, transfer_loss: 0.0165, total_Loss: 0.2774
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.8412981455064193 F1_MA: 0.3613939771432233
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2294   15  335    0]
 [   0    1   50    3]
 [   0   11   63    7]
 [   0    8   16    1]]
Epoch: [23/200], cls_loss: 0.2571, transfer_loss: 0.0188, total_Loss: 0.2665
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9443651925820257 F1_MA: 0.4432769446952839
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2611   21    1   11]
 [   5    9    3   37]
 [   1   20   22   38]
 [   1   12    6    6]]
Epoch: [24/200], cls_loss: 0.2314, transfer_loss: 0.0194, total_Loss: 0.2411
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9461483594864479 F1_MA: 0.39197874004405775
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2640    3    1    0]
 [  45    5    0    4]
 [  34   22    1   24]
 [  13    5    0    7]]
Epoch: [25/200], cls_loss: 0.2650, transfer_loss: 0.0191, total_Loss: 0.2745
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9497146932952925 F1_MA: 0.5392756697692862
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2621   23    0    0]
 [  16   38    0    0]
 [  12   63    1    5]
 [   5   17    0    3]]
Epoch: [26/200], cls_loss: 0.2249, transfer_loss: 0.0166, total_Loss: 0.2331
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.5766761768901569 F1_MA: 0.31098293075969946
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[1552   18 1074    0]
 [   0    3   51    0]
 [   0   16   62    3]
 [   0   11   14    0]]
Epoch: [27/200], cls_loss: 0.2324, transfer_loss: 0.0171, total_Loss: 0.2409
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.019614835948644792 F1_MA: 0.13250010024186878
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[   0 2640    4    0]
 [   0   47    6    1]
 [   0   73    8    0]
 [   0   20    5    0]]
Epoch: [28/200], cls_loss: 0.2073, transfer_loss: 0.0204, total_Loss: 0.2175
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9504279600570613 F1_MA: 0.3982776946364593
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2636    1    5    2]
 [  28    0    9   17]
 [  24    3   21   33]
 [  10    0    7    8]]
Epoch: [29/200], cls_loss: 0.1945, transfer_loss: 0.0149, total_Loss: 0.2020
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9101283880171184 F1_MA: 0.37635499127067035
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2519  122    0    3]
 [   0   29    3   22]
 [   1   63    3   14]
 [   1   19    4    1]]
Epoch: [30/200], cls_loss: 0.1960, transfer_loss: 0.0206, total_Loss: 0.2063
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.15905848787446505 F1_MA: 0.2921967059355919
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[ 368    2 2274    0]
 [   0    2   52    0]
 [   1    3   76    1]
 [   0    3   22    0]]
Epoch: [31/200], cls_loss: 0.1926, transfer_loss: 0.0181, total_Loss: 0.2016
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.6815263908701854 F1_MA: 0.3156482485328188
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[1853  133  658    0]
 [   0    8   46    0]
 [   0   30   50    1]
 [   0   14   11    0]]
Epoch: [32/200], cls_loss: 0.1793, transfer_loss: 0.0220, total_Loss: 0.1903
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9400855920114122 F1_MA: 0.4193496548669296
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2560    2   82    0]
 [   2    1   50    1]
 [   1    1   75    4]
 [   2    2   21    0]]
Epoch: [33/200], cls_loss: 0.1775, transfer_loss: 0.0178, total_Loss: 0.1864
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9204707560627675 F1_MA: 0.4068786216191581
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2530   82   32    0]
 [   1   15   33    5]
 [   3   33   34   11]
 [   0   16    7    2]]
Epoch: [34/200], cls_loss: 0.1983, transfer_loss: 0.0202, total_Loss: 0.2084
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9461483594864479 F1_MA: 0.3894895031991793
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2603   27   14    0]
 [   6    7   41    0]
 [   8   30   43    0]
 [   1   13   11    0]]
Epoch: [35/200], cls_loss: 0.1831, transfer_loss: 0.0206, total_Loss: 0.1934
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.8673323823109843 F1_MA: 0.4740300991539378
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2360  256   28    0]
 [   0    8   45    1]
 [   0   16   60    5]
 [   0   13    8    4]]
Epoch: [36/200], cls_loss: 0.1601, transfer_loss: 0.0184, total_Loss: 0.1693
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.9165477888730386 F1_MA: 0.39695847555555996
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2515  103   26    0]
 [   1   21   32    0]
 [   0   46   34    1]
 [   0   15   10    0]]
Epoch: [37/200], cls_loss: 0.1732, transfer_loss: 0.0198, total_Loss: 0.1830
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.93188302425107 F1_MA: 0.5034475053049715
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2554   83    5    2]
 [   3   37    8    6]
 [   3   55   17    6]
 [   0   17    3    5]]
Epoch: [38/200], cls_loss: 0.1577, transfer_loss: 0.0221, total_Loss: 0.1687
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.025320970042796005 F1_MA: 0.1180415356759528
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[   0    4 2637    3]
 [   0    1   49    4]
 [   0    7   65    9]
 [   0   10   10    5]]
Epoch: [39/200], cls_loss: 0.1649, transfer_loss: 0.0168, total_Loss: 0.1733
trian begin
trian end
n_person 565
SAMPLE
F1_MI: 0.8830242510699001 F1_MA: 0.5152328611137775
BEST_F1_MI: 0.9604136947218259 BEST_F1_MA: 0.5463415669600552
[[2407  230    7    0]
 [   0   42   10    2]
 [   0   54   24    3]
 [   0   17    5    3]]
Epoch: [40/200], cls_loss: 0.1587, transfer_loss: 0.0205, total_Loss: 0.1689
[[2625   19    0    0]
 [   7   39    1    7]
 [   4   60    4   13]
 [   3   15    0    7]]
[[2636    6    2    0]
 [  16   17   20    1]
 [  15   29   34    3]
 [   4   11    4    6]]
ARG: Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=30, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, max_iter=20000, momentum=0.9, n_class=4, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='77G', tgt_domain='own', tname='transfer', transfer_loss='lmmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
CL_weight [1, 1, 1, 1]

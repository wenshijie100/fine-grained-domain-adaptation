bash: root@container-c6d2118b3c-3e3131f9:/home/DeepDA-P#: No such file or directory
bash: nphup: command not found
bash: ohup: command not found
nohup: ignoring input
usage: main.py [-h] [--config CONFIG] [--seed SEED]
               [--num_workers NUM_WORKERS] [--backbone BACKBONE]
               [--use_bottleneck USE_BOTTLENECK] --data_dir DATA_DIR
               --src_domain SRC_DOMAIN --tgt_domain TGT_DOMAIN --tname TNAME
               [--batch_size BATCH_SIZE] [--n_epoch N_EPOCH]
               [--early_stop EARLY_STOP]
               [--epoch_based_training EPOCH_BASED_TRAINING]
               [--n_iter_per_epoch N_ITER_PER_EPOCH] [--lr LR]
               [--momentum MOMENTUM] [--weight_decay WEIGHT_DECAY]
               [--lr_gamma LR_GAMMA] [--lr_decay LR_DECAY]
               [--lr_scheduler LR_SCHEDULER]
               [--transfer_loss_weight TRANSFER_LOSS_WEIGHT]
               [--transfer_loss TRANSFER_LOSS]
main.py: error: the following arguments are required: --src_domain
nohup: ignoring input
usage: main.py [-h] [--config CONFIG] [--seed SEED]
               [--num_workers NUM_WORKERS] [--backbone BACKBONE]
               [--use_bottleneck USE_BOTTLENECK] --data_dir DATA_DIR
               --src_domain SRC_DOMAIN --tgt_domain TGT_DOMAIN --tname TNAME
               [--batch_size BATCH_SIZE] [--n_epoch N_EPOCH]
               [--early_stop EARLY_STOP]
               [--epoch_based_training EPOCH_BASED_TRAINING]
               [--n_iter_per_epoch N_ITER_PER_EPOCH] [--lr LR]
               [--momentum MOMENTUM] [--weight_decay WEIGHT_DECAY]
               [--lr_gamma LR_GAMMA] [--lr_decay LR_DECAY]
               [--lr_scheduler LR_SCHEDULER]
               [--transfer_loss_weight TRANSFER_LOSS_WEIGHT]
               [--transfer_loss TRANSFER_LOSS]
main.py: error: unrecognized arguments: lmmd
nohup: ignoring input
lmmd 2022 UCI WISDM DAN/DAN.yaml
Namespace(backbone='resnet50', batch_size=256, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, momentum=0.9, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='UCI', tgt_domain='WISDM', tname='transfer', transfer_loss='lmmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
JUST DO IT
run my Parkinson code
transfer
TRAIN Length: 3369 615 TEST Length: 13609 322
DATA_PROFILE   train: 3369 train2: 13609 test: 13609
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f5739839070> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f57312b8eb0> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f57314abfd0> False
CLASS: 4 322
LLL: {}
BOTTLENECK_LIST: [Linear(in_features=512, out_features=256, bias=True), ReLU()]
TYPE: {'loss_type': 'lmmd', 'max_iter': 20000, 'num_class': 4, 'my_person_item': <my_person_item.PersonItem object at 0x7f57312b8910>}
KWARGS {'my_person_item': <my_person_item.PersonItem object at 0x7f57312b8910>}
TransferNet(
  (base_network): ResNet(
    (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (4): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (5): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(256, 512, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (avgpool): AdaptiveAvgPool1d(output_size=1)
  )
  (bottleneck_layer): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): ReLU()
  )
  (classifier_layer): Linear(in_features=256, out_features=4, bias=True)
  (adapt_loss): TransferLoss(
    (loss_func): LMMDLoss()
  )
  (criterion): CrossEntropyLoss()
)
initial_lr 1.0
1.8.1+cu111
True
LEN: 0 0
LOADER: <data_loader.InfiniteDataLoader object at 0x7f57312b80a0> <data_loader.InfiniteDataLoader object at 0x7f5731346520>
N: 100
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.2460871482107429 BEST_F1_MA: 0.4212245467921312
[[ 282 6263 1710    3]
 [ 218 1856  165  102]
 [ 208 1546  106   41]
 [   0    4    0 1105]]
Epoch: [ 1/200], cls_loss: 0.2010, transfer_loss: 0.0006, total_Loss: 0.2013, test_loss 7.759652
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.2759938276140789 BEST_F1_MA: 0.4227785368269754
[[1538 1273 5445    2]
 [1166  551  548   76]
 [ 892  416  562   31]
 [   2    2    0 1105]]
Epoch: [ 2/200], cls_loss: 0.0138, transfer_loss: 0.0020, total_Loss: 0.0148, test_loss 11.083640
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3361011095598501 BEST_F1_MA: 0.45881974565785266
[[2017 2368 3871    2]
 [ 783 1130  333   95]
 [ 814  718  321   48]
 [   1    2    0 1106]]
Epoch: [ 3/200], cls_loss: 0.0037, transfer_loss: 0.0020, total_Loss: 0.0047, test_loss 5.481565
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3361011095598501 BEST_F1_MA: 0.45881974565785266
[[ 595 4037 3614   12]
 [ 419 1457  280  185]
 [ 391 1084  346   80]
 [   1    3    0 1105]]
Epoch: [ 4/200], cls_loss: 0.0084, transfer_loss: 0.0015, total_Loss: 0.0091, test_loss 6.435680
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3361011095598501 BEST_F1_MA: 0.45881974565785266
[[ 499 5376 2378    5]
 [ 164 1984  128   65]
 [ 279 1467  109   46]
 [   0    5    0 1104]]
Epoch: [ 5/200], cls_loss: 0.0078, transfer_loss: 0.0019, total_Loss: 0.0088, test_loss 4.988725
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3361011095598501 BEST_F1_MA: 0.45881974565785266
[[1667 2981 3561   49]
 [ 529 1055  399  358]
 [ 733  602  362  204]
 [   1    0    0 1108]]
Epoch: [ 6/200], cls_loss: 0.0062, transfer_loss: 0.0018, total_Loss: 0.0071, test_loss 5.763254
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3361011095598501 BEST_F1_MA: 0.4744916478202828
[[ 848 3273 4128    9]
 [ 307 1635  289  110]
 [ 399  976  460   66]
 [   1    2    0 1106]]
Epoch: [ 7/200], cls_loss: 0.0029, transfer_loss: 0.0015, total_Loss: 0.0036, test_loss 6.583787
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.34021603350723784 BEST_F1_MA: 0.4744916478202828
[[2243 1389 4612   14]
 [ 922  735  486  198]
 [ 886  381  544   90]
 [   1    0    0 1108]]
Epoch: [ 8/200], cls_loss: 0.0056, transfer_loss: 0.0018, total_Loss: 0.0065, test_loss 7.062098
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.34021603350723784 BEST_F1_MA: 0.4744916478202828
[[1722 3295 3232    9]
 [ 721 1222  282  116]
 [ 787  784  263   67]
 [   1    1    0 1107]]
Epoch: [ 9/200], cls_loss: 0.0023, transfer_loss: 0.0013, total_Loss: 0.0030, test_loss 6.081349
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4744916478202828
[[3602 2173 2435   48]
 [ 829  863  264  385]
 [ 941  519  237  204]
 [   1    0    0 1108]]
Epoch: [10/200], cls_loss: 0.0042, transfer_loss: 0.0019, total_Loss: 0.0052, test_loss 8.396526
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4744916478202828
[[1826 1987 4441    4]
 [ 799  966  386  190]
 [ 789  499  545   68]
 [   1    1    0 1107]]
Epoch: [11/200], cls_loss: 0.0070, transfer_loss: 0.0038, total_Loss: 0.0089, test_loss 36.056778
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[2755 2736 2765    2]
 [ 605 1345  287  104]
 [ 829  805  241   26]
 [   0    4    0 1105]]
Epoch: [12/200], cls_loss: 0.0106, transfer_loss: 0.0035, total_Loss: 0.0123, test_loss 6.852626
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[ 647 2982 4606   23]
 [ 339 1269  520  213]
 [ 389  855  574   83]
 [   1    2    0 1106]]
Epoch: [13/200], cls_loss: 0.0040, transfer_loss: 0.0020, total_Loss: 0.0049, test_loss 8.933861
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[ 714 3401 4137    6]
 [ 272 1564  367  138]
 [ 329 1048  454   70]
 [   0    2    0 1107]]
Epoch: [14/200], cls_loss: 0.0032, transfer_loss: 0.0014, total_Loss: 0.0039, test_loss 6.763514
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[2293 2722 3237    6]
 [ 563 1251  350  177]
 [ 718  753  349   81]
 [   1    1    0 1107]]
Epoch: [15/200], cls_loss: 0.0005, transfer_loss: 0.0006, total_Loss: 0.0008, test_loss 6.797010
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[1954 3059 3230   15]
 [ 534 1215  312  280]
 [ 684  779  320  118]
 [   1    1    0 1107]]
Epoch: [16/200], cls_loss: 0.0000, transfer_loss: 0.0002, total_Loss: 0.0001, test_loss 7.408028
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[2274 2888 3068   28]
 [ 481 1218  349  293]
 [ 686  756  330  129]
 [   0    2    0 1107]]
Epoch: [17/200], cls_loss: 0.0006, transfer_loss: 0.0006, total_Loss: 0.0008, test_loss 7.314182
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4269233595414799 BEST_F1_MA: 0.4907607089674529
[[2573 2492 3182   11]
 [ 696 1164  372  109]
 [ 797  686  362   56]
 [   0    7    0 1102]]
Epoch: [18/200], cls_loss: 0.0034, transfer_loss: 0.0013, total_Loss: 0.0040, test_loss 5.815167
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[4330 2197 1626  105]
 [ 750 1033  305  253]
 [ 934  637  215  115]
 [   0    2    1 1106]]
Epoch: [19/200], cls_loss: 0.0052, transfer_loss: 0.0016, total_Loss: 0.0060, test_loss 5.849760
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2797 2589 2861   11]
 [ 641 1174  333  193]
 [ 727  821  257   96]
 [   1    1    0 1107]]
Epoch: [20/200], cls_loss: 0.0031, transfer_loss: 0.0024, total_Loss: 0.0043, test_loss 6.182947
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2015 2828 3378   37]
 [ 649 1088  308  296]
 [ 722  802  257  120]
 [   1    1    0 1107]]
Epoch: [21/200], cls_loss: 0.0020, transfer_loss: 0.0007, total_Loss: 0.0024, test_loss 7.826649
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2188 1373 4687   10]
 [ 655  718  805  163]
 [ 840  459  521   81]
 [   1    0    3 1105]]
Epoch: [22/200], cls_loss: 0.0057, transfer_loss: 0.0012, total_Loss: 0.0063, test_loss 7.475892
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2090 2603 3558    7]
 [ 843  918  329  251]
 [ 820  696  287   98]
 [   1    1    0 1107]]
Epoch: [23/200], cls_loss: 0.0039, transfer_loss: 0.0022, total_Loss: 0.0050, test_loss 6.587450
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2065 2595 3574   24]
 [ 537 1069  435  300]
 [ 620  794  362  125]
 [   1    2    0 1106]]
Epoch: [24/200], cls_loss: 0.0016, transfer_loss: 0.0011, total_Loss: 0.0021, test_loss 7.022425
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[3071 1899 3270   18]
 [ 651  837  507  346]
 [ 806  543  421  131]
 [   1    1    0 1107]]
Epoch: [25/200], cls_loss: 0.0027, transfer_loss: 0.0012, total_Loss: 0.0033, test_loss 5.466155
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2877 2248 3115   18]
 [ 542 1049  466  284]
 [ 727  634  419  121]
 [   0    2    0 1107]]
Epoch: [26/200], cls_loss: 0.0006, transfer_loss: 0.0008, total_Loss: 0.0010, test_loss 6.043129
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1774 2610 3822   52]
 [ 807  787  422  325]
 [ 714  590  438  159]
 [   1    2    0 1106]]
Epoch: [27/200], cls_loss: 0.0015, transfer_loss: 0.0020, total_Loss: 0.0025, test_loss 15.622559
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[ 766 2651 4731  110]
 [ 649  561  617  514]
 [ 534  517  650  200]
 [   1    1    0 1107]]
Epoch: [28/200], cls_loss: 0.0034, transfer_loss: 0.0032, total_Loss: 0.0050, test_loss 6.944651
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1617 3490 3000  151]
 [ 182 1311  440  408]
 [ 284  911  442  264]
 [   0    4    0 1105]]
Epoch: [29/200], cls_loss: 0.0042, transfer_loss: 0.0041, total_Loss: 0.0062, test_loss 6.499238
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2383 2121 3697   57]
 [ 635  655  677  374]
 [ 579  457  655  210]
 [   0    1    1 1107]]
Epoch: [30/200], cls_loss: 0.0019, transfer_loss: 0.0009, total_Loss: 0.0023, test_loss 6.722327
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1677 2169 4254  158]
 [ 298  791  718  534]
 [ 374  523  695  309]
 [   0    1    1 1107]]
Epoch: [31/200], cls_loss: 0.0017, transfer_loss: 0.0005, total_Loss: 0.0020, test_loss 9.035113
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2186 2602 3449   21]
 [ 424 1228  458  231]
 [ 501  812  454  134]
 [   0    1    2 1106]]
Epoch: [32/200], cls_loss: 0.0025, transfer_loss: 0.0021, total_Loss: 0.0035, test_loss 6.237485
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1927 2121 4171   39]
 [ 640 1074  425  202]
 [ 586  688  509  118]
 [   0    3    0 1106]]
Epoch: [33/200], cls_loss: 0.0019, transfer_loss: 0.0008, total_Loss: 0.0023, test_loss 6.005647
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2091 2846 3281   40]
 [ 545 1188  358  250]
 [ 497  848  408  148]
 [   0    2    0 1107]]
Epoch: [34/200], cls_loss: 0.0010, transfer_loss: 0.0010, total_Loss: 0.0015, test_loss 6.544992
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2334 2681 3161   82]
 [ 465 1065  377  434]
 [ 435  818  421  227]
 [   1    0    1 1107]]
Epoch: [35/200], cls_loss: 0.0013, transfer_loss: 0.0006, total_Loss: 0.0016, test_loss 6.931510
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2143 2789 3264   62]
 [ 456 1087  375  423]
 [ 445  801  441  214]
 [   1    1    0 1107]]
Epoch: [36/200], cls_loss: 0.0000, transfer_loss: 0.0003, total_Loss: 0.0002, test_loss 7.192806
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2139 4073 2029   17]
 [ 478 1388  179  296]
 [ 426 1156  179  140]
 [   1    1    0 1107]]
Epoch: [37/200], cls_loss: 0.0026, transfer_loss: 0.0010, total_Loss: 0.0031, test_loss 5.950121
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[3013 2054 3165   26]
 [ 731  865  355  390]
 [ 809  520  379  193]
 [   1    1    0 1107]]
Epoch: [38/200], cls_loss: 0.0037, transfer_loss: 0.0015, total_Loss: 0.0044, test_loss 5.416971
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[ 935 2974 4312   37]
 [ 567 1020  329  425]
 [ 419  742  497  243]
 [   1    1    0 1107]]
Epoch: [39/200], cls_loss: 0.0002, transfer_loss: 0.0005, total_Loss: 0.0005, test_loss 7.980625
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1761 2600 3865   32]
 [ 474 1040  423  404]
 [ 554  639  495  213]
 [   1    1    0 1107]]
Epoch: [40/200], cls_loss: 0.0023, transfer_loss: 0.0014, total_Loss: 0.0030, test_loss 9.768493
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[ 694 4291 3245   28]
 [ 532 1208  278  323]
 [ 516  757  412  216]
 [   1    1    0 1107]]
Epoch: [41/200], cls_loss: 0.0022, transfer_loss: 0.0020, total_Loss: 0.0032, test_loss 7.836148
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1588 2690 3965   15]
 [ 975  719  356  291]
 [ 834  372  524  171]
 [   2    0    0 1107]]
Epoch: [42/200], cls_loss: 0.0017, transfer_loss: 0.0009, total_Loss: 0.0021, test_loss 7.247214
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1268 3635 3331   24]
 [ 558 1123  325  335]
 [ 607  657  449  188]
 [   0    2    0 1107]]
Epoch: [43/200], cls_loss: 0.0007, transfer_loss: 0.0004, total_Loss: 0.0009, test_loss 7.467271
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1573 2930 3712   43]
 [ 580 1042  298  421]
 [ 645  607  383  266]
 [   1    1    0 1107]]
Epoch: [44/200], cls_loss: 0.0027, transfer_loss: 0.0014, total_Loss: 0.0033, test_loss 6.806757
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[3234 2379 2621   24]
 [ 973  742  269  357]
 [1064  381  239  217]
 [   1    1    1 1106]]
Epoch: [45/200], cls_loss: 0.0020, transfer_loss: 0.0007, total_Loss: 0.0024, test_loss 5.850255
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[3076 2149 2999   34]
 [ 791  900  342  308]
 [ 788  499  417  197]
 [   1    2    0 1106]]
Epoch: [46/200], cls_loss: 0.0001, transfer_loss: 0.0010, total_Loss: 0.0006, test_loss 6.399032
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[3558 1734 2850  116]
 [ 427  870  559  485]
 [ 588  461  563  289]
 [   0    4    2 1103]]
Epoch: [47/200], cls_loss: 0.0024, transfer_loss: 0.0012, total_Loss: 0.0030, test_loss 4.525862
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[3806 1950 2466   36]
 [ 596 1006  339  400]
 [ 812  579  306  204]
 [   1    2    0 1106]]
Epoch: [48/200], cls_loss: 0.0033, transfer_loss: 0.0021, total_Loss: 0.0044, test_loss 5.326783
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[1939 3180 3120   19]
 [ 415 1063  484  379]
 [ 380  722  578  221]
 [   1    0    1 1107]]
Epoch: [49/200], cls_loss: 0.0022, transfer_loss: 0.0012, total_Loss: 0.0028, test_loss 6.300574
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4907607089674529
[[2738 2341 3150   29]
 [ 468  849  657  367]
 [ 586  506  615  194]
 [   1    0    1 1107]]
Epoch: [50/200], cls_loss: 0.0011, transfer_loss: 0.0006, total_Loss: 0.0014, test_loss 6.397276
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4916633209451854
[[3242 1846 3136   34]
 [ 493  849  681  318]
 [ 575  504  662  160]
 [   1    2    0 1106]]
Epoch: [51/200], cls_loss: 0.0008, transfer_loss: 0.0006, total_Loss: 0.0011, test_loss 6.026586
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4916633209451854
[[3524 2058 2587   89]
 [ 408  924  515  494]
 [ 517  546  595  243]
 [   1    0    0 1108]]
Epoch: [52/200], cls_loss: 0.0000, transfer_loss: 0.0003, total_Loss: 0.0002, test_loss 6.192981
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4987368262218169
[[2520 2507 3184   47]
 [ 292 1054  594  401]
 [ 292  645  759  205]
 [   0    1    1 1107]]
Epoch: [53/200], cls_loss: 0.0024, transfer_loss: 0.0009, total_Loss: 0.0028, test_loss 5.199244
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4987368262218169
[[2172 2824 3220   42]
 [ 437 1218  371  315]
 [ 425  810  507  159]
 [   1    1    0 1107]]
Epoch: [54/200], cls_loss: 0.0001, transfer_loss: 0.0005, total_Loss: 0.0003, test_loss 7.236839
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4987368262218169
[[2793 2824 2592   49]
 [ 395 1287  357  302]
 [ 449  848  435  169]
 [   0    2    0 1107]]
Epoch: [55/200], cls_loss: 0.0003, transfer_loss: 0.0005, total_Loss: 0.0005, test_loss 6.301387
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.4987368262218169
[[2327 2572 3300   59]
 [ 388 1227  446  280]
 [ 332  792  614  163]
 [   0    1    1 1107]]
Epoch: [56/200], cls_loss: 0.0020, transfer_loss: 0.0014, total_Loss: 0.0027, test_loss 6.433497
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5032733523777594
[[3596 2585 1993   84]
 [ 467 1164  389  321]
 [ 506  709  487  199]
 [   0    2    0 1107]]
Epoch: [57/200], cls_loss: 0.0000, transfer_loss: 0.0002, total_Loss: 0.0002, test_loss 5.814898
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2062 3055 3106   35]
 [ 335 1236  526  244]
 [ 278  791  703  129]
 [   0    2    0 1107]]
Epoch: [58/200], cls_loss: 0.0052, transfer_loss: 0.0011, total_Loss: 0.0058, test_loss 5.234523
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[4255 2399 1567   37]
 [ 953  853  210  325]
 [ 981  606  167  147]
 [   1    1    0 1107]]
Epoch: [59/200], cls_loss: 0.0018, transfer_loss: 0.0011, total_Loss: 0.0024, test_loss 5.108108
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2587 2878 2778   15]
 [ 734 1116  171  320]
 [ 697  851  232  121]
 [   0    2    0 1107]]
Epoch: [60/200], cls_loss: 0.0029, transfer_loss: 0.0013, total_Loss: 0.0036, test_loss 6.144515
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1391 2941 3904   22]
 [ 289 1523  217  312]
 [ 376 1148  278   99]
 [   0    2    0 1107]]
Epoch: [61/200], cls_loss: 0.0044, transfer_loss: 0.0014, total_Loss: 0.0051, test_loss 6.585369
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1508 2970 3748   32]
 [ 395 1348  217  381]
 [ 550  905  286  160]
 [   1    1    0 1107]]
Epoch: [62/200], cls_loss: 0.0003, transfer_loss: 0.0007, total_Loss: 0.0007, test_loss 7.308750
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1329 3997 2789  143]
 [ 280 1158  231  672]
 [ 417  842  308  334]
 [   0    2    0 1107]]
Epoch: [63/200], cls_loss: 0.0033, transfer_loss: 0.0012, total_Loss: 0.0039, test_loss 6.199934
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2090 2936 3193   39]
 [ 480 1205  309  347]
 [ 618  820  311  152]
 [   1    1    0 1107]]
Epoch: [64/200], cls_loss: 0.0005, transfer_loss: 0.0006, total_Loss: 0.0008, test_loss 6.474649
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2151 2449 3618   40]
 [ 469 1039  429  404]
 [ 606  703  398  194]
 [   1    1    0 1107]]
Epoch: [65/200], cls_loss: 0.0021, transfer_loss: 0.0012, total_Loss: 0.0027, test_loss 6.277202
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1718 2696 3804   40]
 [ 448  965  431  497]
 [ 542  695  420  244]
 [   1    1    0 1107]]
Epoch: [66/200], cls_loss: 0.0001, transfer_loss: 0.0005, total_Loss: 0.0003, test_loss 7.527571
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1564 3398 3223   73]
 [ 332 1114  292  603]
 [ 506  825  280  290]
 [   0    2    0 1107]]
Epoch: [67/200], cls_loss: 0.0019, transfer_loss: 0.0006, total_Loss: 0.0022, test_loss 6.303629
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2056 2640 3526   36]
 [ 708  826  376  431]
 [ 810  570  325  196]
 [   2    1    0 1106]]
Epoch: [68/200], cls_loss: 0.0006, transfer_loss: 0.0006, total_Loss: 0.0009, test_loss 7.347860
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1981 2972 3295   10]
 [ 659 1059  361  262]
 [ 825  683  302   91]
 [   0    3    1 1105]]
Epoch: [69/200], cls_loss: 0.0003, transfer_loss: 0.0005, total_Loss: 0.0005, test_loss 6.488878
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2567 2878 2768   45]
 [ 755  829  288  469]
 [ 923  482  258  238]
 [   0    2    0 1107]]
Epoch: [70/200], cls_loss: 0.0010, transfer_loss: 0.0009, total_Loss: 0.0015, test_loss 6.095421
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1777 1261 5204   16]
 [1070  577  403  291]
 [ 919  430  451  101]
 [   3    1    0 1105]]
Epoch: [71/200], cls_loss: 0.0037, transfer_loss: 0.0018, total_Loss: 0.0046, test_loss 7.322089
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1992 1936 4311   19]
 [ 861  667  406  407]
 [ 974  452  293  182]
 [   1    1    0 1107]]
Epoch: [72/200], cls_loss: 0.0016, transfer_loss: 0.0008, total_Loss: 0.0020, test_loss 6.843885
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2686 2245 3313   14]
 [ 858  861  278  344]
 [1036  560  166  139]
 [   1    2    0 1106]]
Epoch: [73/200], cls_loss: 0.0013, transfer_loss: 0.0008, total_Loss: 0.0017, test_loss 6.241748
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[4065 1917 2254   22]
 [1139  517  326  359]
 [1246  316  179  160]
 [   1    1    0 1107]]
Epoch: [74/200], cls_loss: 0.0014, transfer_loss: 0.0007, total_Loss: 0.0018, test_loss 5.589065
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1347 2324 4487  100]
 [ 655  552  471  663]
 [ 685  310  501  405]
 [   1    1    0 1107]]
Epoch: [75/200], cls_loss: 0.0017, transfer_loss: 0.0008, total_Loss: 0.0021, test_loss 7.866910
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1118 2629 4436   75]
 [ 568  705  515  553]
 [ 573  539  491  298]
 [   1    0    1 1107]]
Epoch: [76/200], cls_loss: 0.0025, transfer_loss: 0.0009, total_Loss: 0.0030, test_loss 7.800473
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1420 2199 4572   67]
 [ 678  595  512  556]
 [ 736  404  481  280]
 [   1    0    1 1107]]
Epoch: [77/200], cls_loss: 0.0003, transfer_loss: 0.0003, total_Loss: 0.0004, test_loss 7.891708
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1375 2200 4630   53]
 [ 507 1039  350  445]
 [ 670  638  394  199]
 [   0    2    0 1107]]
Epoch: [78/200], cls_loss: 0.0004, transfer_loss: 0.0004, total_Loss: 0.0006, test_loss 7.665350
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1576 1298 5326   58]
 [ 701  503  551  586]
 [ 841  300  474  286]
 [   0    2    0 1107]]
Epoch: [79/200], cls_loss: 0.0005, transfer_loss: 0.0003, total_Loss: 0.0007, test_loss 7.023422
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1299 2298 4621   40]
 [ 482  999  369  491]
 [ 630  665  392  214]
 [   0    2    0 1107]]
Epoch: [80/200], cls_loss: 0.0024, transfer_loss: 0.0011, total_Loss: 0.0030, test_loss 7.181935
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1627 2045 4520   66]
 [ 417  864  503  557]
 [ 540  584  503  274]
 [   0    2    0 1107]]
Epoch: [81/200], cls_loss: 0.0010, transfer_loss: 0.0006, total_Loss: 0.0013, test_loss 7.212354
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1658 2334 4206   60]
 [ 410 1009  445  477]
 [ 550  668  445  238]
 [   0    2    0 1107]]
Epoch: [82/200], cls_loss: 0.0001, transfer_loss: 0.0002, total_Loss: 0.0002, test_loss 7.529547
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2187 2326 3696   49]
 [ 591  993  424  333]
 [ 801  518  380  202]
 [   0    2    0 1107]]
Epoch: [83/200], cls_loss: 0.0028, transfer_loss: 0.0010, total_Loss: 0.0032, test_loss 6.537492
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1751 2163 4233  111]
 [ 631  805  405  500]
 [ 771  471  370  289]
 [   0    2    0 1107]]
Epoch: [84/200], cls_loss: 0.0005, transfer_loss: 0.0004, total_Loss: 0.0008, test_loss 7.239221
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1758 1818 4658   24]
 [ 473 1242  382  244]
 [ 597  795  389  120]
 [   0    3    0 1106]]
Epoch: [85/200], cls_loss: 0.0029, transfer_loss: 0.0009, total_Loss: 0.0034, test_loss 6.266758
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[ 783 2580 4801   94]
 [ 534  866  429  512]
 [ 487  655  461  298]
 [   0    2    0 1107]]
Epoch: [86/200], cls_loss: 0.0022, transfer_loss: 0.0007, total_Loss: 0.0026, test_loss 7.849087
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2311 2320 3569   58]
 [ 621  822  439  459]
 [ 687  570  412  232]
 [   1    1    0 1107]]
Epoch: [87/200], cls_loss: 0.0009, transfer_loss: 0.0004, total_Loss: 0.0011, test_loss 6.545164
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1234 2298 4692   34]
 [ 289 1343  382  327]
 [ 451  902  368  180]
 [   0    2    0 1107]]
Epoch: [88/200], cls_loss: 0.0001, transfer_loss: 0.0003, total_Loss: 0.0002, test_loss 7.363599
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[ 892 1987 5288   91]
 [ 334 1139  406  462]
 [ 489  761  429  222]
 [   0    2    0 1107]]
Epoch: [89/200], cls_loss: 0.0001, transfer_loss: 0.0002, total_Loss: 0.0002, test_loss 7.859104
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1270 2207 4772    9]
 [ 443 1417  250  231]
 [ 595  909  304   93]
 [   0    3    0 1106]]
Epoch: [90/200], cls_loss: 0.0021, transfer_loss: 0.0012, total_Loss: 0.0027, test_loss 6.616084
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1172 1408 5624   54]
 [ 566  933  264  578]
 [ 646  622  375  258]
 [   0    2    0 1107]]
Epoch: [91/200], cls_loss: 0.0001, transfer_loss: 0.0004, total_Loss: 0.0003, test_loss 7.575174
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1875 1562 4780   41]
 [ 486 1021  363  471]
 [ 646  641  422  192]
 [   0    2    0 1107]]
Epoch: [92/200], cls_loss: 0.0032, transfer_loss: 0.0006, total_Loss: 0.0035, test_loss 6.337019
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1621 2295 4235  107]
 [ 321 1032  354  634]
 [ 390  784  426  301]
 [   0    2    0 1107]]
Epoch: [93/200], cls_loss: 0.0014, transfer_loss: 0.0005, total_Loss: 0.0016, test_loss 7.039375
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1879 2256 4006  117]
 [ 372 1045  276  648]
 [ 451  749  395  306]
 [   0    2    0 1107]]
Epoch: [94/200], cls_loss: 0.0009, transfer_loss: 0.0006, total_Loss: 0.0012, test_loss 6.761152
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1276 2684 4220   78]
 [ 323 1186  305  527]
 [ 362  877  430  232]
 [   0    2    0 1107]]
Epoch: [95/200], cls_loss: 0.0009, transfer_loss: 0.0004, total_Loss: 0.0011, test_loss 7.272673
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1449 3041 3680   88]
 [ 522 1028  261  530]
 [ 451  847  375  228]
 [   2    0    0 1107]]
Epoch: [96/200], cls_loss: 0.0012, transfer_loss: 0.0003, total_Loss: 0.0014, test_loss 6.216361
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1910 2550 3542  256]
 [ 400  842  242  857]
 [ 524  645  330  402]
 [   0    1    0 1108]]
Epoch: [97/200], cls_loss: 0.0014, transfer_loss: 0.0006, total_Loss: 0.0017, test_loss 6.883663
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2567 2308 3241  142]
 [ 551  819  266  705]
 [ 614  587  355  345]
 [   1    1    0 1107]]
Epoch: [98/200], cls_loss: 0.0007, transfer_loss: 0.0003, total_Loss: 0.0009, test_loss 5.863896
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1816 2711 3581  150]
 [ 334  891  313  803]
 [ 416  647  414  424]
 [   1    4    0 1104]]
Epoch: [99/200], cls_loss: 0.0009, transfer_loss: 0.0005, total_Loss: 0.0012, test_loss 7.042952
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2120 2735 3241  162]
 [ 269  860  378  834]
 [ 398  579  509  415]
 [   0    5    0 1104]]
Epoch: [100/200], cls_loss: 0.0005, transfer_loss: 0.0003, total_Loss: 0.0006, test_loss 6.690345
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2772 2788 2543  155]
 [ 141 1085  443  672]
 [ 223  706  631  341]
 [   0    2    0 1107]]
Epoch: [101/200], cls_loss: 0.0036, transfer_loss: 0.0010, total_Loss: 0.0041, test_loss 5.690500
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2673 2761 2696  128]
 [ 332  871  666  472]
 [ 494  535  619  253]
 [   1    0    4 1104]]
Epoch: [102/200], cls_loss: 0.0016, transfer_loss: 0.0007, total_Loss: 0.0020, test_loss 5.608228
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2478 3404 2172  204]
 [ 248  833  500  760]
 [ 368  536  552  445]
 [   1    0    4 1104]]
Epoch: [103/200], cls_loss: 0.0006, transfer_loss: 0.0005, total_Loss: 0.0008, test_loss 6.399953
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1992 2600 3505  161]
 [ 182  810  816  533]
 [ 215  413  959  314]
 [   1    0    4 1104]]
Epoch: [104/200], cls_loss: 0.0013, transfer_loss: 0.0006, total_Loss: 0.0016, test_loss 5.838770
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[1285 2868 3888  217]
 [ 473  880  459  529]
 [ 286  504  769  342]
 [   3    0    1 1105]]
Epoch: [105/200], cls_loss: 0.0006, transfer_loss: 0.0005, total_Loss: 0.0009, test_loss 7.132304
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2554 2406 3066  232]
 [ 504  846  443  548]
 [ 405  563  650  283]
 [   1    3    0 1105]]
Epoch: [106/200], cls_loss: 0.0001, transfer_loss: 0.0003, total_Loss: 0.0002, test_loss 6.382288
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[3236 2492 2318  212]
 [ 294 1023  402  622]
 [ 425  692  508  276]
 [   0    4    0 1105]]
Epoch: [107/200], cls_loss: 0.0003, transfer_loss: 0.0005, total_Loss: 0.0005, test_loss 5.912331
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.49114556543463883 BEST_F1_MA: 0.5048022671618378
[[2624 2504 2920  210]
 [ 269  861  531  680]
 [ 326  616  625  334]
 [   0    3    0 1106]]
Epoch: [108/200], cls_loss: 0.0012, transfer_loss: 0.0005, total_Loss: 0.0015, test_loss 5.867308
[[2062 3055 3106   35]
 [ 335 1236  526  244]
 [ 278  791  703  129]
 [   0    2    0 1107]]
[[4330 2197 1626  105]
 [ 750 1033  305  253]
 [ 934  637  215  115]
 [   0    2    1 1106]]
ARG: Namespace(backbone='resnet50', batch_size=256, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, max_iter=20000, momentum=0.9, n_class=4, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='UCI', tgt_domain='WISDM', tname='transfer', transfer_loss='lmmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
CL_weight [1, 1, 1, 1]

nohup: ignoring input
lmmd 2022 77G 45 DAN/DAN.yaml
Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, momentum=0.9, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='77G', tgt_domain='45', tname='transfer', transfer_loss='lmmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
JUST DO IT
run my Parkinson code
transfer
TRAIN Length: 2593 255 TEST Length: 55571 1995
DATA_PROFILE   train: 2593 train2: 55571 test: 55571
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f405cd2c100> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f405ca96f40> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f4054712c40> False
CLASS: 4 1995
LLL: {}
BOTTLENECK_LIST: [Linear(in_features=512, out_features=256, bias=True), ReLU()]
TYPE: {'loss_type': 'lmmd', 'max_iter': 20000, 'num_class': 4, 'my_person_item': <my_person_item.PersonItem object at 0x7f40549dd190>}
KWARGS {'my_person_item': <my_person_item.PersonItem object at 0x7f40549dd190>}
TransferNet(
  (base_network): ResNet(
    (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (4): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (5): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(256, 512, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (avgpool): AdaptiveAvgPool1d(output_size=1)
  )
  (bottleneck_layer): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): ReLU()
  )
  (classifier_layer): Linear(in_features=256, out_features=4, bias=True)
  (adapt_loss): TransferLoss(
    (loss_func): LMMDLoss()
  )
  (criterion): CrossEntropyLoss()
)
initial_lr 1.0
1.8.1+cu111
True
LEN: 0 0
LOADER: <data_loader.InfiniteDataLoader object at 0x7f405ca89850> <data_loader.InfiniteDataLoader object at 0x7f405479c970>
N: 100
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.21558006874089003 BEST_F1_MA: 0.3261355042900876
[[ 5767 36449   431    12]
 [   98  5760   183    11]
 [    8  6051   453    15]
 [    0   255    78     0]]
Epoch: [ 1/200], cls_loss: 0.8023, transfer_loss: 0.0006, total_Loss: 0.8026, test_loss 2.338322
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.3913192132587141 BEST_F1_MA: 0.4170924338300733
[[15556 24303  1966   834]
 [  235  4793   651   373]
 [   20  4379  1226   902]
 [    2    77    83   171]]
Epoch: [ 2/200], cls_loss: 0.6510, transfer_loss: 0.0016, total_Loss: 0.6519, test_loss 1.495695
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.3951521477029386 BEST_F1_MA: 0.4170924338300733
[[15822 26514   269    54]
 [  180  5620   171    81]
 [    7  5904   488   128]
 [    0   182   122    29]]
Epoch: [ 3/200], cls_loss: 0.6172, transfer_loss: 0.0032, total_Loss: 0.6188, test_loss 1.456606
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.48894207410339924 BEST_F1_MA: 0.4170924338300733
[[22660 11231  5302  3466]
 [ 1133  2447  1305  1167]
 [  616  2469  1850  1592]
 [    8    38    73   214]]
Epoch: [ 4/200], cls_loss: 0.5579, transfer_loss: 0.0056, total_Loss: 0.5608, test_loss 1.511049
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.6033182775188498 BEST_F1_MA: 0.4170924338300733
[[30554 11665   404    36]
 [ 3293  2541   151    67]
 [ 2124  3908   417    78]
 [   67   177    74    15]]
Epoch: [ 5/200], cls_loss: 0.5051, transfer_loss: 0.0049, total_Loss: 0.5076, test_loss 1.033519
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.6033182775188498 BEST_F1_MA: 0.4170924338300733
[[26679 15172   588   220]
 [ 2112  3477   309   154]
 [  924  4303   948   352]
 [   19   173    57    84]]
Epoch: [ 6/200], cls_loss: 0.5378, transfer_loss: 0.0075, total_Loss: 0.5415, test_loss 1.034833
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.6033182775188498 BEST_F1_MA: 0.4170924338300733
[[    5 32224 10405    25]
 [    3  3219  2803    27]
 [    0  3446  3033    48]
 [    0   114   205    14]]
Epoch: [ 7/200], cls_loss: 0.4609, transfer_loss: 0.0077, total_Loss: 0.4647, test_loss 2.963716
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.6033182775188498 BEST_F1_MA: 0.4170924338300733
[[26919  9291  5397  1052]
 [ 2173  2156  1316   407]
 [ 1295  2567  1971   694]
 [   41    49   100   143]]
Epoch: [ 8/200], cls_loss: 0.4239, transfer_loss: 0.0088, total_Loss: 0.4283, test_loss 1.228811
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.6677943531698188 BEST_F1_MA: 0.4170924338300733
[[35534  6830   160   135]
 [ 4511  1404    46    91]
 [ 2660  3568   134   165]
 [   91   200     4    38]]
Epoch: [ 9/200], cls_loss: 0.3944, transfer_loss: 0.0093, total_Loss: 0.3991, test_loss 1.811851
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.6677943531698188 BEST_F1_MA: 0.4170924338300733
[[25788 12009  3456  1406]
 [ 1879  2604   944   625]
 [ 1105  3452  1308   662]
 [   26   123    69   115]]
Epoch: [10/200], cls_loss: 0.3719, transfer_loss: 0.0095, total_Loss: 0.3767, test_loss 1.244265
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[38055  3394  1095   115]
 [ 5114   598   284    56]
 [ 3996  1931   554    46]
 [  248    42    33    10]]
Epoch: [11/200], cls_loss: 0.3670, transfer_loss: 0.0109, total_Loss: 0.3725, test_loss 1.493422
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[34344  6661  1493   161]
 [ 4330  1302   316   104]
 [ 3225  2643   580    79]
 [  182   109    21    21]]
Epoch: [12/200], cls_loss: 0.3888, transfer_loss: 0.0132, total_Loss: 0.3954, test_loss 1.237423
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[25835  7529  8872   423]
 [ 1991  1247  2642   172]
 [  953  1891  3460   223]
 [   26    45   208    54]]
Epoch: [13/200], cls_loss: 0.3521, transfer_loss: 0.0144, total_Loss: 0.3593, test_loss 1.393540
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[ 2808 38248  1570    33]
 [   35  5705   303     9]
 [   15  6065   422    25]
 [    4   291    32     6]]
Epoch: [14/200], cls_loss: 0.3279, transfer_loss: 0.0181, total_Loss: 0.3369, test_loss 2.566121
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[  252  3365 38446   596]
 [   81   385  5362   224]
 [    3  1010  5037   477]
 [    1    14   193   125]]
Epoch: [15/200], cls_loss: 0.3585, transfer_loss: 0.0168, total_Loss: 0.3669, test_loss 6.743744
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[31034 10274  1137   214]
 [ 3342  2329   301    80]
 [ 1751  3932   709   135]
 [   55   158    48    72]]
Epoch: [16/200], cls_loss: 0.3143, transfer_loss: 0.0151, total_Loss: 0.3218, test_loss 1.470095
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[   31   246 42051   331]
 [   11    27  5946    68]
 [    0   449  5983    95]
 [    0     0   303    30]]
Epoch: [17/200], cls_loss: 0.3201, transfer_loss: 0.0166, total_Loss: 0.3283, test_loss 8.514472
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[23187  3877 13866  1729]
 [ 1177   610  3564   701]
 [  526  1074  4359   568]
 [   12    18   164   139]]
Epoch: [18/200], cls_loss: 0.2924, transfer_loss: 0.0174, total_Loss: 0.3012, test_loss 1.716155
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[21099 12737  8224   599]
 [  847  2605  2333   267]
 [  219  2621  3470   217]
 [    3    57   203    70]]
Epoch: [19/200], cls_loss: 0.3092, transfer_loss: 0.0230, total_Loss: 0.3207, test_loss 1.718671
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[16353 25802   375   129]
 [  657  5309    51    35]
 [  195  6210   102    20]
 [    6   292    14    21]]
Epoch: [20/200], cls_loss: 0.2663, transfer_loss: 0.0179, total_Loss: 0.2752, test_loss 2.570285
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[ 1425 38853  2308    73]
 [  225  5289   500    38]
 [   98  5355  1050    24]
 [    1   185   117    30]]
Epoch: [21/200], cls_loss: 0.2702, transfer_loss: 0.0156, total_Loss: 0.2780, test_loss 3.530695
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[22278  4074  8823  7484]
 [ 1480   633  2166  1773]
 [  394  1027  3503  1603]
 [   14    14   155   150]]
Epoch: [22/200], cls_loss: 0.3085, transfer_loss: 0.0190, total_Loss: 0.3180, test_loss 2.285003
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[17475 23870  1218    96]
 [  457  5138   381    76]
 [  202  5479   785    61]
 [    3   216    57    57]]
Epoch: [23/200], cls_loss: 0.2770, transfer_loss: 0.0161, total_Loss: 0.2851, test_loss 1.726208
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[24798 15688  2086    87]
 [ 2006  3662   376     8]
 [ 1052  4676   781    18]
 [   31   187   104    11]]
Epoch: [24/200], cls_loss: 0.2526, transfer_loss: 0.0165, total_Loss: 0.2608, test_loss 1.445250
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[17554 15951  8691   463]
 [  383  2614  2841   214]
 [   67  2889  3401   170]
 [    3    69   210    51]]
Epoch: [25/200], cls_loss: 0.2399, transfer_loss: 0.0165, total_Loss: 0.2482, test_loss 1.895690
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[31758  5960  3916  1025]
 [ 3730  1128   993   201]
 [ 2369  2307  1709   142]
 [   92    66    78    97]]
Epoch: [26/200], cls_loss: 0.2720, transfer_loss: 0.0177, total_Loss: 0.2809, test_loss 1.376619
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[18048   922 23121   568]
 [  972    67  4804   209]
 [  413   633  5230   251]
 [   14     5   204   110]]
Epoch: [27/200], cls_loss: 0.2368, transfer_loss: 0.0213, total_Loss: 0.2474, test_loss 2.592983
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[ 1507  6540  7180 27432]
 [  314  1171  1849  2718]
 [   91  2245  2431  1760]
 [   14    64   124   131]]
Epoch: [28/200], cls_loss: 0.2352, transfer_loss: 0.0203, total_Loss: 0.2453, test_loss 4.331543
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[13044 24560  4230   825]
 [  366  4410  1066   210]
 [  113  4561  1666   187]
 [    3   142   117    71]]
Epoch: [29/200], cls_loss: 0.2247, transfer_loss: 0.0237, total_Loss: 0.2365, test_loss 2.423187
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[30145 10698  1557   259]
 [ 3093  2473   403    83]
 [ 1922  3851   691    63]
 [   80   128    59    66]]
Epoch: [30/200], cls_loss: 0.2001, transfer_loss: 0.0210, total_Loss: 0.2106, test_loss 1.300614
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[22161 13011  6736   751]
 [ 1031  2917  1873   231]
 [  338  3769  2280   140]
 [    6   102   190    35]]
Epoch: [31/200], cls_loss: 0.2373, transfer_loss: 0.0244, total_Loss: 0.2495, test_loss 1.931971
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[ 2999  1755 11028 26877]
 [  666   210  2441  2735]
 [  496   811  3033  2187]
 [    5     7   110   211]]
Epoch: [32/200], cls_loss: 0.2043, transfer_loss: 0.0194, total_Loss: 0.2140, test_loss 5.154751
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[32127  5259  5216    57]
 [ 3230   922  1863    37]
 [ 2130  1834  2539    24]
 [   54    71   193    15]]
Epoch: [33/200], cls_loss: 0.2139, transfer_loss: 0.0221, total_Loss: 0.2249, test_loss 1.477293
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[19934  3914 15971  2840]
 [  944   477  3857   774]
 [  312  1171  4602   442]
 [    5    18   244    66]]
Epoch: [34/200], cls_loss: 0.2111, transfer_loss: 0.0234, total_Loss: 0.2228, test_loss 2.216355
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[30403  4548  7414   294]
 [ 2971   664  2313   104]
 [ 2166  1522  2791    48]
 [   69    40   206    18]]
Epoch: [35/200], cls_loss: 0.2192, transfer_loss: 0.0205, total_Loss: 0.2294, test_loss 1.631498
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[35165  4626  2576   292]
 [ 4488   864   557   143]
 [ 3436  1935  1023   133]
 [  145    50    53    85]]
Epoch: [36/200], cls_loss: 0.2280, transfer_loss: 0.0248, total_Loss: 0.2404, test_loss 1.775151
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[17162 19339  5867   291]
 [  346  3956  1623   127]
 [   42  4591  1802    92]
 [    2   165   140    26]]
Epoch: [37/200], cls_loss: 0.2288, transfer_loss: 0.0346, total_Loss: 0.2461, test_loss 2.262731
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[  255  2808 39071   525]
 [   42   380  5493   137]
 [   18  1138  5243   128]
 [    3    20   252    58]]
Epoch: [38/200], cls_loss: 0.1843, transfer_loss: 0.0233, total_Loss: 0.1960, test_loss 4.441297
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[17943  4381 20276    59]
 [  484   603  4920    45]
 [  141  1408  4949    29]
 [    2    31   296     4]]
Epoch: [39/200], cls_loss: 0.1701, transfer_loss: 0.0170, total_Loss: 0.1786, test_loss 2.577403
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[28916 11619  1829   295]
 [ 3038  2449   460   105]
 [ 1874  3595   964    94]
 [   78   105    59    91]]
Epoch: [40/200], cls_loss: 0.1758, transfer_loss: 0.0192, total_Loss: 0.1854, test_loss 1.758010
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[32185  1949  6967  1558]
 [ 3321   183  1982   566]
 [ 2522   743  2728   534]
 [   59     9   109   156]]
Epoch: [41/200], cls_loss: 0.1625, transfer_loss: 0.0198, total_Loss: 0.1724, test_loss 1.867796
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[32788  7456  2378    37]
 [ 3998  1495   532    27]
 [ 3107  2638   764    18]
 [  131    82   102    18]]
Epoch: [42/200], cls_loss: 0.1842, transfer_loss: 0.0197, total_Loss: 0.1941, test_loss 1.720460
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[23173 10363  9067    56]
 [ 1637  2075  2280    60]
 [  872  3192  2447    16]
 [   33   134   147    19]]
Epoch: [43/200], cls_loss: 0.1682, transfer_loss: 0.0247, total_Loss: 0.1805, test_loss 1.943545
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[36899  3877  1742   141]
 [ 5036   599   356    61]
 [ 4582  1181   719    45]
 [  190    43    61    39]]
Epoch: [44/200], cls_loss: 0.1472, transfer_loss: 0.0237, total_Loss: 0.1591, test_loss 2.043487
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[ 9723  2046 30724   166]
 [  109   233  5641    69]
 [   42   878  5494   113]
 [    2     7   272    52]]
Epoch: [45/200], cls_loss: 0.1610, transfer_loss: 0.0259, total_Loss: 0.1739, test_loss 5.103217
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[   25  3408 38972   254]
 [    2   558  5420    72]
 [    1  1384  5099    43]
 [    2    41   279    11]]
Epoch: [46/200], cls_loss: 0.1883, transfer_loss: 0.0286, total_Loss: 0.2026, test_loss 5.812248
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[29984 10025  2640    10]
 [ 3163  2352   528     9]
 [ 2187  3394   936    10]
 [   87   137   101     8]]
Epoch: [47/200], cls_loss: 0.1464, transfer_loss: 0.0202, total_Loss: 0.1565, test_loss 1.454949
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[   26  3398 38781   454]
 [    2   432  5530    88]
 [    0  1210  5229    88]
 [    0    32   285    16]]
Epoch: [48/200], cls_loss: 0.1431, transfer_loss: 0.0192, total_Loss: 0.1527, test_loss 5.424618
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[29179  7612  5785    83]
 [ 2885  1508  1627    32]
 [ 2027  2354  2132    14]
 [   74    88   150    21]]
Epoch: [49/200], cls_loss: 0.1402, transfer_loss: 0.0180, total_Loss: 0.1493, test_loss 2.018681
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[  508  3303 38144   704]
 [   81   380  5395   196]
 [   28  1024  5296   179]
 [    2    21   256    54]]
Epoch: [50/200], cls_loss: 0.1385, transfer_loss: 0.0206, total_Loss: 0.1488, test_loss 4.777184
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[  570  6325 35435   329]
 [   76   985  4879   112]
 [    2  1453  4947   125]
 [    2    30   261    40]]
Epoch: [51/200], cls_loss: 0.1440, transfer_loss: 0.0237, total_Loss: 0.1558, test_loss 5.374171
trian begin
trian end
n_person 1995
SAMPLE
BEST_F1_MI: 0.7057098126720771 BEST_F1_MA: 0.4170924338300733
[[16736  7566 18274    83]
 [  484  1213  4305    50]
 [  148  1896  4430    53]
 [    3    64   241    25]]
Epoch: [52/200], cls_loss: 0.1371, transfer_loss: 0.0183, total_Loss: 0.1463, test_loss 3.060816
[[15556 24303  1966   834]
 [  235  4793   651   373]
 [   20  4379  1226   902]
 [    2    77    83   171]]
[[38055  3394  1095   115]
 [ 5114   598   284    56]
 [ 3996  1931   554    46]
 [  248    42    33    10]]
ARG: Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, max_iter=20000, momentum=0.9, n_class=4, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='77G', tgt_domain='45', tname='transfer', transfer_loss='lmmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
CL_weight [1, 1, 1, 1]
nohup: ignoring input
mmd 2022 77G 45 DAN/DAN.yaml
Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, momentum=0.9, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='77G', tgt_domain='45', tname='transfer', transfer_loss='mmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
JUST DO IT
run my Parkinson code
transfer
TRAIN Length: 2593 255 TEST Length: 55571 1995
DATA_PROFILE   train: 2593 train2: 55571 test: 55571
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f6f72d6a730> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f6f72ad0f40> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f6f6a74d8e0> False
CLASS: 4 1995
LLL: {}
BOTTLENECK_LIST: [Linear(in_features=512, out_features=256, bias=True), ReLU()]
TYPE: {'loss_type': 'mmd', 'max_iter': 20000, 'num_class': 4, 'my_person_item': <my_person_item.PersonItem object at 0x7f6f6a773d60>}
TransferNet(
  (base_network): ResNet(
    (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (4): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (5): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(256, 512, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (avgpool): AdaptiveAvgPool1d(output_size=1)
  )
  (bottleneck_layer): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): ReLU()
  )
  (classifier_layer): Linear(in_features=256, out_features=4, bias=True)
  (adapt_loss): TransferLoss(
    (loss_func): MMDLoss()
  )
  (criterion): CrossEntropyLoss()
)
initial_lr 1.0
transfer_world
1.8.1+cu111
True
LEN: 0 0
LOADER: <data_loader.InfiniteDataLoader object at 0x7f6f72ab6850> <data_loader.InfiniteDataLoader object at 0x7f6f6a74dc40>
N: 100
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.366797868078269
[[28935 13430   279    15]
 [ 2578  3402    68     4]
 [ 1526  4382   548    71]
 [   30   277    25     1]]
Epoch: [ 1/200], cls_loss: 0.8664, transfer_loss: 0.0760, total_Loss: 0.9044, test_loss 1.029357
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.36699055481032883
[[    3 42155   315   186]
 [    0  5828    91   133]
 [    0  5852   297   378]
 [    0   181    45   107]]
Epoch: [ 2/200], cls_loss: 0.6760, transfer_loss: 0.0540, total_Loss: 0.7030, test_loss 2.438324
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4131076780404128
[[26084 14472  1317   786]
 [ 1847  3471   382   352]
 [  875  3555   958  1139]
 [   19    87    53   174]]
Epoch: [ 3/200], cls_loss: 0.6373, transfer_loss: 0.0484, total_Loss: 0.6615, test_loss 0.984419
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4131076780404128
[[24418 17886   290    65]
 [ 1525  4374    81    72]
 [  452  5733   214   128]
 [    4   260    52    17]]
Epoch: [ 4/200], cls_loss: 0.5849, transfer_loss: 0.0528, total_Loss: 0.6113, test_loss 0.901099
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4131076780404128
[[23164 18381   971   143]
 [ 1221  4324   409    98]
 [  325  4953   997   252]
 [    3   131   156    43]]
Epoch: [ 5/200], cls_loss: 0.5670, transfer_loss: 0.0509, total_Loss: 0.5925, test_loss 1.301735
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4131076780404128
[[11225 15879 11646  3909]
 [   75  1534  2896  1547]
 [    2   622  2931  2972]
 [    0    10    71   252]]
Epoch: [ 6/200], cls_loss: 0.5740, transfer_loss: 0.0623, total_Loss: 0.6052, test_loss 1.960241
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[27702 13338   968   651]
 [ 2291  3191   265   305]
 [ 1088  3627   988   824]
 [   23    94    60   156]]
Epoch: [ 7/200], cls_loss: 0.5072, transfer_loss: 0.0539, total_Loss: 0.5342, test_loss 1.041498
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[25678 15764   965   252]
 [ 1850  3692   317   193]
 [  813  4370   743   601]
 [   17   125    57   134]]
Epoch: [ 8/200], cls_loss: 0.4554, transfer_loss: 0.0508, total_Loss: 0.4808, test_loss 1.149723
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[12856 19892  8444  1467]
 [  194  3266  1915   677]
 [   30  2596  2426  1475]
 [    1    50    82   200]]
Epoch: [ 9/200], cls_loss: 0.4457, transfer_loss: 0.0593, total_Loss: 0.4754, test_loss 2.067170
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[18434 19545  4325   355]
 [  395  4453  1000   204]
 [   46  4720  1343   418]
 [    2   142    79   110]]
Epoch: [10/200], cls_loss: 0.4188, transfer_loss: 0.0569, total_Loss: 0.4473, test_loss 1.662931
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[29245  7590  3950  1874]
 [ 2785  1731   732   804]
 [ 1774  2557   767  1429]
 [   52    56    22   203]]
Epoch: [11/200], cls_loss: 0.4275, transfer_loss: 0.0591, total_Loss: 0.4571, test_loss 1.226015
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[19324  5138 17967   230]
 [  662   784  4432   174]
 [  209  1133  4833   352]
 [    8    27   240    58]]
Epoch: [12/200], cls_loss: 0.4206, transfer_loss: 0.0592, total_Loss: 0.4502, test_loss 2.144090
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[20881  4442 16580   756]
 [  742   791  4099   420]
 [  281   967  4341   938]
 [    7    26   172   128]]
Epoch: [13/200], cls_loss: 0.3914, transfer_loss: 0.0566, total_Loss: 0.4197, test_loss 2.065462
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[18750 21637  2223    49]
 [  428  5068   509    47]
 [  111  5552   780    84]
 [    3   242    60    28]]
Epoch: [14/200], cls_loss: 0.3525, transfer_loss: 0.0652, total_Loss: 0.3851, test_loss 2.140880
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[22971 19133   420   135]
 [ 1251  4657    55    89]
 [  451  5654   247   175]
 [   37   236    29    31]]
Epoch: [15/200], cls_loss: 0.3817, transfer_loss: 0.0625, total_Loss: 0.4129, test_loss 1.594711
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[27511 13581   339  1228]
 [ 2568  2812    35   637]
 [ 1377  3437   213  1500]
 [   47    60    23   203]]
Epoch: [16/200], cls_loss: 0.3338, transfer_loss: 0.0598, total_Loss: 0.3637, test_loss 1.370912
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.5917834841913948 BEST_F1_MA: 0.4177538466501726
[[   94  3288 39117   160]
 [   30   380  5536   106]
 [    4  1280  5095   148]
 [    3    19   259    52]]
Epoch: [17/200], cls_loss: 0.3346, transfer_loss: 0.0568, total_Loss: 0.3630, test_loss 5.390817
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6379406524986054 BEST_F1_MA: 0.4177538466501726
[[32931  7076  1422  1230]
 [ 4036  1371   275   370]
 [ 2808  2146  1058   515]
 [  117    44    81    91]]
Epoch: [18/200], cls_loss: 0.3174, transfer_loss: 0.0659, total_Loss: 0.3504, test_loss 1.415385
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6379406524986054 BEST_F1_MA: 0.4177538466501726
[[    5 39576  2004  1074]
 [    1  5242   331   478]
 [    0  4725   816   986]
 [    0   125    59   149]]
Epoch: [19/200], cls_loss: 0.3226, transfer_loss: 0.0673, total_Loss: 0.3562, test_loss 3.138282
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6379406524986054 BEST_F1_MA: 0.4177538466501726
[[12278 29223   364   794]
 [  117  5578    26   331]
 [   12  5795   100   620]
 [    2   190    18   123]]
Epoch: [20/200], cls_loss: 0.2967, transfer_loss: 0.0585, total_Loss: 0.3260, test_loss 2.688158
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6379406524986054 BEST_F1_MA: 0.4177538466501726
[[ 7101 29216  4420  1922]
 [  444  3947   768   893]
 [  119  3920  1193  1295]
 [    3    80    49   201]]
Epoch: [21/200], cls_loss: 0.2884, transfer_loss: 0.0651, total_Loss: 0.3209, test_loss 2.424169
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6379406524986054 BEST_F1_MA: 0.4177538466501726
[[12985  6092 23350   232]
 [  118  1024  4867    43]
 [   23  2213  4196    95]
 [    3    43   268    19]]
Epoch: [22/200], cls_loss: 0.3097, transfer_loss: 0.0623, total_Loss: 0.3409, test_loss 2.952457
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6379406524986054 BEST_F1_MA: 0.4177538466501726
[[    3   193 41825   638]
 [    1    13  5860   178]
 [    2   471  5840   214]
 [    0     0   287    46]]
Epoch: [23/200], cls_loss: 0.2797, transfer_loss: 0.0662, total_Loss: 0.3128, test_loss 4.927361
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[33277  4550  4690   142]
 [ 4139   832  1003    78]
 [ 2789  2284  1385    69]
 [  152    84    76    21]]
Epoch: [24/200], cls_loss: 0.2531, transfer_loss: 0.0732, total_Loss: 0.2896, test_loss 1.422853
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[20971  2358 19074   256]
 [ 1691   374  3887   100]
 [  965  1508  3966    88]
 [   52    50   198    33]]
Epoch: [25/200], cls_loss: 0.2547, transfer_loss: 0.0696, total_Loss: 0.2895, test_loss 2.328767
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[   22   233 41482   922]
 [    1    14  5867   170]
 [    5   245  5979   298]
 [    0     1   271    61]]
Epoch: [26/200], cls_loss: 0.2579, transfer_loss: 0.0620, total_Loss: 0.2889, test_loss 4.897024
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[19176  6392 15336  1755]
 [  629  1148  3797   478]
 [  147  2327  3459   594]
 [    4    37   159   133]]
Epoch: [27/200], cls_loss: 0.2518, transfer_loss: 0.0646, total_Loss: 0.2841, test_loss 2.073168
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[19842 14606  8062   149]
 [  846  3527  1640    39]
 [  281  4995  1174    77]
 [   10   253    59    11]]
Epoch: [28/200], cls_loss: 0.2497, transfer_loss: 0.0704, total_Loss: 0.2849, test_loss 1.810441
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[12300 24003  6128   228]
 [  255  4218  1518    61]
 [   75  4690  1617   145]
 [    4   202   108    19]]
Epoch: [29/200], cls_loss: 0.2457, transfer_loss: 0.0388, total_Loss: 0.2651, test_loss 2.317273
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[ 8734 16822 16419   684]
 [   63  1761  4043   185]
 [   20  2667  3577   263]
 [    2    54   215    62]]
Epoch: [30/200], cls_loss: 0.2172, transfer_loss: 0.0686, total_Loss: 0.2515, test_loss 2.412661
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[ 5335   719 30038  6567]
 [   19    90  4461  1482]
 [    2   727  4583  1215]
 [    2     3   190   138]]
Epoch: [31/200], cls_loss: 0.2416, transfer_loss: 0.0670, total_Loss: 0.2751, test_loss 4.074609
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[  715  5523 36166   255]
 [   33   960  4977    82]
 [   12  2360  4018   137]
 [    2    45   223    63]]
Epoch: [32/200], cls_loss: 0.2265, transfer_loss: 0.0690, total_Loss: 0.2610, test_loss 4.536032
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[ 9409  1309 31615   326]
 [   95   146  5717    94]
 [    8   854  5488   177]
 [    4    12   297    20]]
Epoch: [33/200], cls_loss: 0.2352, transfer_loss: 0.0645, total_Loss: 0.2674, test_loss 3.212011
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[20842 16708  5006   103]
 [  952  3559  1510    31]
 [  228  5130  1110    59]
 [    5   222    98     8]]
Epoch: [34/200], cls_loss: 0.2132, transfer_loss: 0.0585, total_Loss: 0.2424, test_loss 1.918493
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[18747   823  9593 13496]
 [  533   110  2025  3384]
 [   94   704  2280  3449]
 [    5     6    36   286]]
Epoch: [35/200], cls_loss: 0.2087, transfer_loss: 0.0705, total_Loss: 0.2439, test_loss 2.552690
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[28694  4464  6376  3125]
 [ 2594   910  1453  1095]
 [ 1920  2252  1777   578]
 [   81    47   120    85]]
Epoch: [36/200], cls_loss: 0.2227, transfer_loss: 0.0574, total_Loss: 0.2514, test_loss 1.995967
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[28245  9201  4025  1188]
 [ 2605  2285   726   436]
 [ 1613  3207  1485   222]
 [   80    48   168    37]]
Epoch: [37/200], cls_loss: 0.2074, transfer_loss: 0.0438, total_Loss: 0.2293, test_loss 1.739124
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[18635 21189  2176   659]
 [  817  4423   539   273]
 [  296  5539   582   110]
 [   19   213    62    39]]
Epoch: [38/200], cls_loss: 0.1953, transfer_loss: 0.0667, total_Loss: 0.2287, test_loss 1.828344
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[ 3613 29375  9211   460]
 [   71  3045  2801   135]
 [   13  3325  3022   167]
 [    2    81   196    54]]
Epoch: [39/200], cls_loss: 0.1765, transfer_loss: 0.0691, total_Loss: 0.2110, test_loss 3.629060
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[25762  6308  9579  1010]
 [ 1791  1187  2717   357]
 [  945  2151  3120   311]
 [   30    51   166    86]]
Epoch: [40/200], cls_loss: 0.1769, transfer_loss: 0.0680, total_Loss: 0.2109, test_loss 1.869154
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[27710  1480 13003   466]
 [ 2292   176  3378   206]
 [ 1288   909  4155   175]
 [   53    13   214    53]]
Epoch: [41/200], cls_loss: 0.1650, transfer_loss: 0.0680, total_Loss: 0.1990, test_loss 1.771965
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[26840  1483 13789   547]
 [ 1913   182  3752   205]
 [ 1047   938  4280   262]
 [   27    10   204    92]]
Epoch: [42/200], cls_loss: 0.1829, transfer_loss: 0.0644, total_Loss: 0.2151, test_loss 1.703381
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[11277   649 30026   707]
 [  520    52  5234   246]
 [  121   813  5289   304]
 [    4     3   208   118]]
Epoch: [43/200], cls_loss: 0.1694, transfer_loss: 0.0647, total_Loss: 0.2018, test_loss 3.122502
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[ 2237  1086 38881   455]
 [  301   134  5480   137]
 [   62   888  5427   150]
 [    3    12   228    90]]
Epoch: [44/200], cls_loss: 0.1677, transfer_loss: 0.0683, total_Loss: 0.2019, test_loss 4.379014
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[23945 14835  3744   135]
 [ 1426  3649   909    68]
 [  546  4648  1282    51]
 [    6   196   109    22]]
Epoch: [45/200], cls_loss: 0.1688, transfer_loss: 0.0630, total_Loss: 0.2003, test_loss 1.885099
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[24954  9674  7897   134]
 [ 1561  1876  2559    56]
 [  741  3213  2532    41]
 [   20   110   187    16]]
Epoch: [46/200], cls_loss: 0.1741, transfer_loss: 0.0722, total_Loss: 0.2102, test_loss 2.059263
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[27725  8785  5668   481]
 [ 2362  2077  1427   186]
 [ 1214  2938  2150   225]
 [   33    96   111    93]]
Epoch: [47/200], cls_loss: 0.1433, transfer_loss: 0.0641, total_Loss: 0.1753, test_loss 1.776907
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[19056 17348  5419   836]
 [  698  3652  1343   359]
 [  179  4349  1734   265]
 [    6   144    90    93]]
Epoch: [48/200], cls_loss: 0.1515, transfer_loss: 0.0738, total_Loss: 0.1884, test_loss 2.111622
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[17416 13021 11858   364]
 [  449  2063  3436   104]
 [   98  2589  3689   151]
 [    3    67   216    47]]
Epoch: [49/200], cls_loss: 0.1353, transfer_loss: 0.0676, total_Loss: 0.1690, test_loss 2.754151
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[28247   889 10102  3421]
 [ 2494   132  2393  1033]
 [ 1856   474  3507   690]
 [   63     7   180    83]]
Epoch: [50/200], cls_loss: 0.1488, transfer_loss: 0.0636, total_Loss: 0.1806, test_loss 2.128324
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[13374  3166 24881  1238]
 [  272   466  5030   284]
 [   37  1324  4804   362]
 [    3    58   188    84]]
Epoch: [51/200], cls_loss: 0.1392, transfer_loss: 0.0638, total_Loss: 0.1711, test_loss 3.384850
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[   27  1811 40525   296]
 [    3   272  5713    64]
 [    5  1381  5019   122]
 [    2    37   247    47]]
Epoch: [52/200], cls_loss: 0.1551, transfer_loss: 0.0686, total_Loss: 0.1893, test_loss 6.939977
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[ 8476 29314  3089  1780]
 [   42  4907   701   402]
 [   10  5420   736   361]
 [    2   176    34   121]]
Epoch: [53/200], cls_loss: 0.1490, transfer_loss: 0.0727, total_Loss: 0.1854, test_loss 3.725438
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[29367  4777  6313  2202]
 [ 2575   857  1936   684]
 [ 1990  1915  2280   342]
 [   66    51   118    98]]
Epoch: [54/200], cls_loss: 0.1384, transfer_loss: 0.0743, total_Loss: 0.1755, test_loss 1.859322
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[  503  1394 40569   193]
 [   45   141  5840    26]
 [    8   928  5504    87]
 [    3    10   306    14]]
Epoch: [55/200], cls_loss: 0.1622, transfer_loss: 0.0681, total_Loss: 0.1963, test_loss 5.055324
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[19291 18140  4824   404]
 [  579  4029  1331   113]
 [  163  4769  1431   164]
 [    2   192    85    54]]
Epoch: [56/200], cls_loss: 0.1127, transfer_loss: 0.0628, total_Loss: 0.1441, test_loss 2.476199
trian begin
trian end
n_person 1995
CHECK_CODE <torch.utils.data.dataloader.DataLoader object at 0x7f6f6a773370>
CHECK_CODE 1737
SAMPLE
BEST_F1_MI: 0.6390923323316118 BEST_F1_MA: 0.4177538466501726
[[23628 12503  5259  1269]
 [ 1413  2828  1312   499]
 [  817  3391  2148   171]
 [   42    73   152    66]]
Epoch: [57/200], cls_loss: 0.1215, transfer_loss: 0.0710, total_Loss: 0.1570, test_loss 2.150540
[[27702 13338   968   651]
 [ 2291  3191   265   305]
 [ 1088  3627   988   824]
 [   23    94    60   156]]
[[33277  4550  4690   142]
 [ 4139   832  1003    78]
 [ 2789  2284  1385    69]
 [  152    84    76    21]]
ARG: Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, max_iter=20000, momentum=0.9, n_class=4, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='77G', tgt_domain='45', tname='transfer', transfer_loss='mmd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
CL_weight [1, 1, 1, 1]

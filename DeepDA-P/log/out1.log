nohup: ignoring input
twommd 2022 UCI WISDM DAN/DAN.yaml
Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, momentum=0.9, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='UCI', tgt_domain='WISDM', tname='transfer', transfer_loss='twommd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
JUST DO IT
run my Parkinson code
transfer
TRAIN Length: 3369 615 TEST Length: 13609 322
DATA_PROFILE   train: 3369 train2: 13609 test: 13609
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f3d18a1d7f0> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f3d1049ca30> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f3d10686040> False
CLASS: 4 322
LLL: {}
BOTTLENECK_LIST: [Linear(in_features=512, out_features=256, bias=True), ReLU()]
TYPE: {'loss_type': 'twommd', 'max_iter': 20000, 'num_class': 4, 'my_person_item': <my_person_item.PersonItem object at 0x7f3d104f4730>}
TransferNet(
  (base_network): ResNet(
    (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (4): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (5): BasicBlock(
        (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv1d(256, 512, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): BasicBlock(
        (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (avgpool): AdaptiveAvgPool1d(output_size=1)
  )
  (bottleneck_layer): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): ReLU()
  )
  (classifier_layer): Linear(in_features=256, out_features=4, bias=True)
  (adapt_loss): TransferLoss(
    (loss_func): TWOMMDLoss()
  )
  (criterion): CrossEntropyLoss()
)
initial_lr 1.0
1.8.1+cu111
True
LEN: 0 0
LOADER: <data_loader.InfiniteDataLoader object at 0x7f3d1049cbb0> <data_loader.InfiniteDataLoader object at 0x7f3d1052a760>
N: 100
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.23998824307443603 BEST_F1_MA: 0.43455507007553884
[[ 382 1414 6459    3]
 [ 576  838  833   94]
 [ 300  630  941   30]
 [   2    2    0 1105]]
Epoch: [ 1/200], cls_loss: 0.5811, transfer_loss: 0.0006, total_Loss: 0.5814, test_loss 12.063019
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.24535234036299508 BEST_F1_MA: 0.43455507007553884
[[ 833 3566 3826   33]
 [ 695 1121  318  207]
 [ 557  981  277   86]
 [   1    0    0 1108]]
Epoch: [ 2/200], cls_loss: 0.1554, transfer_loss: 0.0023, total_Loss: 0.1565, test_loss 5.297460
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3052391799544419 BEST_F1_MA: 0.43455507007553884
[[1734 3040 3476    8]
 [ 909 1051  244  137]
 [ 722  867  262   50]
 [   2    0    0 1107]]
Epoch: [ 3/200], cls_loss: 0.1177, transfer_loss: 0.0030, total_Loss: 0.1192, test_loss 5.815705
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3052391799544419 BEST_F1_MA: 0.43455507007553884
[[ 423 3303 4526    6]
 [ 430 1458  372   81]
 [ 369 1041  452   39]
 [   0    3    0 1106]]
Epoch: [ 4/200], cls_loss: 0.0773, transfer_loss: 0.0045, total_Loss: 0.0796, test_loss 8.118863
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3052391799544419 BEST_F1_MA: 0.43455507007553884
[[1647 1692 4864   55]
 [ 617  780  618  326]
 [ 617  587  541  156]
 [   1    2    0 1106]]
Epoch: [ 5/200], cls_loss: 0.0443, transfer_loss: 0.0046, total_Loss: 0.0467, test_loss 5.425144
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.3306635314865163 BEST_F1_MA: 0.4470691921677258
[[1985 1724 4524   25]
 [ 593 1048  436  264]
 [ 705  731  360  105]
 [   1    1    0 1107]]
Epoch: [ 6/200], cls_loss: 0.0358, transfer_loss: 0.0050, total_Loss: 0.0383, test_loss 5.712957
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.46469248291571746 BEST_F1_MA: 0.48939735495982223
[[3947 1517 2785    9]
 [ 887 1022  236  196]
 [ 823  749  248   81]
 [   1    1    0 1107]]
Epoch: [ 7/200], cls_loss: 0.0227, transfer_loss: 0.0037, total_Loss: 0.0245, test_loss 4.424501
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4759350429862591 BEST_F1_MA: 0.5206090749718385
[[3909 1387 2956    6]
 [ 784 1139  332   86]
 [ 901  632  326   42]
 [   1    5    0 1103]]
Epoch: [ 8/200], cls_loss: 0.0559, transfer_loss: 0.0060, total_Loss: 0.0589, test_loss 3.377153
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4759350429862591 BEST_F1_MA: 0.5206090749718385
[[3122 1051 4081    4]
 [1167  781  343   50]
 [1027  409  442   23]
 [   4    0    0 1105]]
Epoch: [ 9/200], cls_loss: 0.0838, transfer_loss: 0.0073, total_Loss: 0.0875, test_loss 5.261157
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.4759350429862591 BEST_F1_MA: 0.5206090749718385
[[2711 2119 3420    8]
 [ 893 1036  221  191]
 [ 784  834  207   76]
 [   2    0    0 1107]]
Epoch: [10/200], cls_loss: 0.0247, transfer_loss: 0.0068, total_Loss: 0.0280, test_loss 5.659605
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5206090749718385
[[4941 1166 1957  194]
 [ 997  751  237  356]
 [1106  433  198  164]
 [   2    1    0 1106]]
Epoch: [11/200], cls_loss: 0.0265, transfer_loss: 0.0053, total_Loss: 0.0291, test_loss 5.899453
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[2391 2441 3413   13]
 [ 380 1617  219  125]
 [ 469 1017  373   42]
 [   0    6    0 1103]]
Epoch: [12/200], cls_loss: 0.0820, transfer_loss: 0.0082, total_Loss: 0.0861, test_loss 9.046605
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[1887 1876 4484   11]
 [ 593 1274  319  155]
 [ 461  927  447   66]
 [   1    2    0 1106]]
Epoch: [13/200], cls_loss: 0.0243, transfer_loss: 0.0085, total_Loss: 0.0285, test_loss 9.920080
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[1818 1681 4747   12]
 [ 723 1014  355  249]
 [ 550  849  415   87]
 [   3    0    0 1106]]
Epoch: [14/200], cls_loss: 0.0439, transfer_loss: 0.0094, total_Loss: 0.0486, test_loss 6.799168
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[2218 2367 3622   51]
 [ 548 1114  288  391]
 [ 577  859  319  146]
 [   1    1    0 1107]]
Epoch: [15/200], cls_loss: 0.0196, transfer_loss: 0.0063, total_Loss: 0.0227, test_loss 5.731848
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[1806 1830 4616    6]
 [ 717 1000  469  155]
 [ 471  767  606   57]
 [   3    1    0 1105]]
Epoch: [16/200], cls_loss: 0.0501, transfer_loss: 0.0059, total_Loss: 0.0531, test_loss 6.090248
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[3775 1307 3173    3]
 [ 910 1041  290  100]
 [ 813  795  261   32]
 [   2    2    1 1104]]
Epoch: [17/200], cls_loss: 0.0309, transfer_loss: 0.0061, total_Loss: 0.0340, test_loss 6.823957
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[3136  982 4128   12]
 [ 962  725  459  195]
 [ 905  471  442   83]
 [   1    2    0 1106]]
Epoch: [18/200], cls_loss: 0.0389, transfer_loss: 0.0101, total_Loss: 0.0440, test_loss 5.728768
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[4548 1391 2298   21]
 [ 962  826  268  285]
 [1094  458  249  100]
 [   2    3    0 1104]]
Epoch: [19/200], cls_loss: 0.0329, transfer_loss: 0.0077, total_Loss: 0.0367, test_loss 4.423806
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[3922 2696 1609   31]
 [ 585  903  491  362]
 [ 742  594  410  155]
 [   1    1    0 1107]]
Epoch: [20/200], cls_loss: 0.0261, transfer_loss: 0.0053, total_Loss: 0.0288, test_loss 4.390482
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5140715702843707 BEST_F1_MA: 0.5217293328143131
[[4192 1404 2581   81]
 [ 791  603  568  379]
 [ 825  386  512  178]
 [   2    1    0 1106]]
Epoch: [21/200], cls_loss: 0.0292, transfer_loss: 0.0096, total_Loss: 0.0340, test_loss 4.101852
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.514953339701668 BEST_F1_MA: 0.5260082907346583
[[4357 1641 2197   63]
 [ 586 1068  475  212]
 [ 630  684  479  108]
 [   1    4    0 1104]]
Epoch: [22/200], cls_loss: 0.0079, transfer_loss: 0.0065, total_Loss: 0.0112, test_loss 3.987070
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.514953339701668 BEST_F1_MA: 0.5291639888893159
[[3497 2540 2037  184]
 [ 266 1273  561  241]
 [ 433  713  619  136]
 [   0    3    3 1103]]
Epoch: [23/200], cls_loss: 0.0166, transfer_loss: 0.0056, total_Loss: 0.0194, test_loss 3.991763
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.514953339701668 BEST_F1_MA: 0.5291639888893159
[[4087 2076 1337  758]
 [ 366 1225  286  464]
 [ 519  786  352  244]
 [   1    3    3 1102]]
Epoch: [24/200], cls_loss: 0.0289, transfer_loss: 0.0096, total_Loss: 0.0337, test_loss 4.241934
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.514953339701668 BEST_F1_MA: 0.5291639888893159
[[4041 1741 1845  631]
 [ 667  618  217  839]
 [ 736  457  216  492]
 [   0    1    0 1108]]
Epoch: [25/200], cls_loss: 0.0339, transfer_loss: 0.0131, total_Loss: 0.0405, test_loss 4.964754
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.514953339701668 BEST_F1_MA: 0.5291639888893159
[[3851 2645 1584  178]
 [ 581 1070  128  562]
 [ 633  769  177  322]
 [   0    2    0 1107]]
Epoch: [26/200], cls_loss: 0.0585, transfer_loss: 0.0119, total_Loss: 0.0644, test_loss 3.940533
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[4338 1528 2124  268]
 [ 524 1313  293  211]
 [ 690  668  335  208]
 [   0    5    0 1104]]
Epoch: [27/200], cls_loss: 0.0125, transfer_loss: 0.0079, total_Loss: 0.0165, test_loss 4.395773
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[2598 1549 4077   34]
 [ 980  823  453   85]
 [ 784  506  526   85]
 [   2    6    0 1101]]
Epoch: [28/200], cls_loss: 0.0209, transfer_loss: 0.0100, total_Loss: 0.0260, test_loss 4.911080
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[3507 1905 2817   29]
 [ 872 1065  175  229]
 [ 935  571  201  194]
 [   2    1    0 1106]]
Epoch: [29/200], cls_loss: 0.0186, transfer_loss: 0.0074, total_Loss: 0.0223, test_loss 4.525551
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[2714 1626 3881   37]
 [ 777  936  454  174]
 [ 604  648  512  137]
 [   0    2    0 1107]]
Epoch: [30/200], cls_loss: 0.0212, transfer_loss: 0.0104, total_Loss: 0.0264, test_loss 4.691262
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[3756 1601 2165  736]
 [ 646 1011  238  446]
 [ 696  660  201  344]
 [   0    5    0 1104]]
Epoch: [31/200], cls_loss: 0.0128, transfer_loss: 0.0070, total_Loss: 0.0163, test_loss 4.562413
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[2726 1113 3701  718]
 [ 836  684  381  440]
 [ 625  452  445  379]
 [   2    3    0 1104]]
Epoch: [32/200], cls_loss: 0.0175, transfer_loss: 0.0091, total_Loss: 0.0220, test_loss 4.834108
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[2315 2533 2703  707]
 [ 451 1214  285  391]
 [ 374  813  412  302]
 [   1    5    0 1103]]
Epoch: [33/200], cls_loss: 0.0136, transfer_loss: 0.0079, total_Loss: 0.0175, test_loss 5.294616
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.5209787640532001 BEST_F1_MA: 0.5291639888893159
[[3474 1042 3654   88]
 [ 814  789  445  293]
 [ 829  435  440  197]
 [   1    6    0 1102]]
Epoch: [34/200], cls_loss: 0.0268, transfer_loss: 0.0079, total_Loss: 0.0307, test_loss 6.560176
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[5291 1068 1784  115]
 [1166  691  249  235]
 [1160  434  171  136]
 [   0    6    1 1102]]
Epoch: [35/200], cls_loss: 0.0309, transfer_loss: 0.0113, total_Loss: 0.0366, test_loss 3.817170
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3425 2880 1666  287]
 [ 577 1070  304  390]
 [ 734  654  230  283]
 [   1    1    0 1107]]
Epoch: [36/200], cls_loss: 0.0314, transfer_loss: 0.0164, total_Loss: 0.0396, test_loss 3.696580
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4112 2043 1950  153]
 [ 792  759  337  453]
 [ 809  497  267  328]
 [   0    2    0 1107]]
Epoch: [37/200], cls_loss: 0.0291, transfer_loss: 0.0127, total_Loss: 0.0354, test_loss 3.738435
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[5057 1604 1440  157]
 [ 794  843  337  367]
 [ 969  544  165  223]
 [   0    4    1 1104]]
Epoch: [38/200], cls_loss: 0.0253, transfer_loss: 0.0112, total_Loss: 0.0309, test_loss 3.976801
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3885 2088 2164  121]
 [ 827  872  282  360]
 [ 783  701  204  213]
 [   2    1    0 1106]]
Epoch: [39/200], cls_loss: 0.0332, transfer_loss: 0.0088, total_Loss: 0.0376, test_loss 4.119640
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3710 1867 2587   94]
 [ 863 1014  160  304]
 [ 849  819   92  141]
 [   0    2    0 1107]]
Epoch: [40/200], cls_loss: 0.0111, transfer_loss: 0.0067, total_Loss: 0.0145, test_loss 4.392355
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[2749 1360 3746  403]
 [ 888  564  378  511]
 [ 744  393  365  399]
 [   2    0    0 1107]]
Epoch: [41/200], cls_loss: 0.0238, transfer_loss: 0.0095, total_Loss: 0.0286, test_loss 5.040439
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[2856 2054 3324   24]
 [ 871  854  375  241]
 [ 823  725  258   95]
 [   1    2    0 1106]]
Epoch: [42/200], cls_loss: 0.0021, transfer_loss: 0.0068, total_Loss: 0.0054, test_loss 5.032803
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4685 1082 2427   64]
 [1304  323  316  398]
 [1368  196  156  181]
 [   2    0    0 1107]]
Epoch: [43/200], cls_loss: 0.0223, transfer_loss: 0.0112, total_Loss: 0.0279, test_loss 4.730129
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3466 1176 3232  384]
 [ 500  927  476  438]
 [ 880  527  233  261]
 [   0    5    0 1104]]
Epoch: [44/200], cls_loss: 0.0303, transfer_loss: 0.0099, total_Loss: 0.0353, test_loss 4.007289
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3432 1403 3048  375]
 [ 603 1046  558  134]
 [ 667  679  407  148]
 [   5    8    1 1095]]
Epoch: [45/200], cls_loss: 0.0183, transfer_loss: 0.0094, total_Loss: 0.0230, test_loss 4.530027
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3767  684 3498  309]
 [ 789  612  368  572]
 [1045  329  190  337]
 [   2    3    0 1104]]
Epoch: [46/200], cls_loss: 0.0254, transfer_loss: 0.0092, total_Loss: 0.0299, test_loss 4.560861
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3815 1130 2752  561]
 [ 363 1049  277  652]
 [ 534  684  210  473]
 [   0    7    0 1102]]
Epoch: [47/200], cls_loss: 0.0134, transfer_loss: 0.0086, total_Loss: 0.0177, test_loss 3.992161
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3689 1067 3054  448]
 [ 684  990  309  358]
 [ 724  677  197  303]
 [   0    7    0 1102]]
Epoch: [48/200], cls_loss: 0.0247, transfer_loss: 0.0091, total_Loss: 0.0292, test_loss 3.764938
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3661 1036 3139  422]
 [ 660 1104  199  378]
 [ 908  580  132  281]
 [   0    7    0 1102]]
Epoch: [49/200], cls_loss: 0.0101, transfer_loss: 0.0102, total_Loss: 0.0152, test_loss 4.427252
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[5089  661 1931  577]
 [ 804  630  338  569]
 [1033  382  142  344]
 [   0    5    0 1104]]
Epoch: [50/200], cls_loss: 0.0265, transfer_loss: 0.0093, total_Loss: 0.0312, test_loss 3.756953
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4134  841 2643  640]
 [ 453 1005  286  597]
 [ 509  636  227  529]
 [   0    5    0 1104]]
Epoch: [51/200], cls_loss: 0.0264, transfer_loss: 0.0083, total_Loss: 0.0305, test_loss 3.961365
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3917  673 3448  220]
 [ 830  726  274  511]
 [ 820  384  288  409]
 [   1    1    0 1107]]
Epoch: [52/200], cls_loss: 0.0214, transfer_loss: 0.0112, total_Loss: 0.0270, test_loss 3.556149
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3216  713 3825  504]
 [ 747  646  312  636]
 [ 990  295  175  441]
 [   0    4    0 1105]]
Epoch: [53/200], cls_loss: 0.0185, transfer_loss: 0.0129, total_Loss: 0.0250, test_loss 4.615886
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[2955  816 4315  172]
 [ 775  765  294  507]
 [1018  357  249  277]
 [   0    1    0 1108]]
Epoch: [54/200], cls_loss: 0.0110, transfer_loss: 0.0095, total_Loss: 0.0158, test_loss 4.996063
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4029  937 2697  595]
 [ 418  887  368  668]
 [ 657  585  235  424]
 [   0    6    0 1103]]
Epoch: [55/200], cls_loss: 0.0132, transfer_loss: 0.0097, total_Loss: 0.0180, test_loss 4.637732
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4179 1275 2304  500]
 [ 546  867  185  743]
 [ 679  566  140  516]
 [   1    1    0 1107]]
Epoch: [56/200], cls_loss: 0.0202, transfer_loss: 0.0108, total_Loss: 0.0256, test_loss 4.056163
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4734 1438 1619  467]
 [ 313  950  397  681]
 [ 465  729  294  413]
 [   1    2    3 1103]]
Epoch: [57/200], cls_loss: 0.0019, transfer_loss: 0.0075, total_Loss: 0.0056, test_loss 4.046431
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4675 1285 2005  293]
 [ 706  840  262  533]
 [ 851  451  209  390]
 [   1    4    0 1104]]
Epoch: [58/200], cls_loss: 0.0149, transfer_loss: 0.0092, total_Loss: 0.0195, test_loss 3.598682
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4352 1584 2239   83]
 [ 916  567  476  382]
 [1008  344  315  234]
 [   2    2    1 1104]]
Epoch: [59/200], cls_loss: 0.0103, transfer_loss: 0.0095, total_Loss: 0.0151, test_loss 3.864725
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3744 1578 2588  348]
 [ 610  757  237  737]
 [ 747  505  244  405]
 [   1    0    0 1108]]
Epoch: [60/200], cls_loss: 0.0172, transfer_loss: 0.0088, total_Loss: 0.0216, test_loss 3.814893
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[2021 2952 3276    9]
 [ 982  729  430  200]
 [ 908  438  453  102]
 [   3    0    0 1106]]
Epoch: [61/200], cls_loss: 0.0197, transfer_loss: 0.0113, total_Loss: 0.0254, test_loss 4.938526
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3991 1714 2495   58]
 [ 832  494  565  450]
 [ 894  283  485  239]
 [   1    0    3 1105]]
Epoch: [62/200], cls_loss: 0.0153, transfer_loss: 0.0088, total_Loss: 0.0198, test_loss 3.930225
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3524 2428 2188  118]
 [ 667  833  414  427]
 [ 745  601  306  249]
 [   1    1    1 1106]]
Epoch: [63/200], cls_loss: 0.0228, transfer_loss: 0.0108, total_Loss: 0.0282, test_loss 4.333370
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3775 3167 1291   25]
 [ 798  475  646  422]
 [ 903  215  582  201]
 [   1    0    2 1106]]
Epoch: [64/200], cls_loss: 0.0094, transfer_loss: 0.0089, total_Loss: 0.0139, test_loss 4.502777
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[5118 1673 1414   53]
 [ 998  815  179  349]
 [1148  454  124  175]
 [   2    0    0 1107]]
Epoch: [65/200], cls_loss: 0.0115, transfer_loss: 0.0106, total_Loss: 0.0168, test_loss 3.615455
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4827 1836 1438  157]
 [ 462 1058  259  562]
 [ 694  758  213  236]
 [   0    1    1 1107]]
Epoch: [66/200], cls_loss: 0.0199, transfer_loss: 0.0106, total_Loss: 0.0252, test_loss 3.312156
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[2389 2362 3477   30]
 [ 728  893  370  350]
 [ 699  555  493  154]
 [   3    0    0 1106]]
Epoch: [67/200], cls_loss: 0.0250, transfer_loss: 0.0113, total_Loss: 0.0306, test_loss 4.772576
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3501 2771 1865  121]
 [ 533 1139  192  477]
 [ 664  859  182  196]
 [   0    2    0 1107]]
Epoch: [68/200], cls_loss: 0.0265, transfer_loss: 0.0118, total_Loss: 0.0324, test_loss 3.679450
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4938 2101 1197   22]
 [1191  623  186  341]
 [1416  231  117  137]
 [   2    0    1 1106]]
Epoch: [69/200], cls_loss: 0.0073, transfer_loss: 0.0117, total_Loss: 0.0131, test_loss 3.926198
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4096 1563 2502   97]
 [ 739  719  463  420]
 [ 857  423  436  185]
 [   1    2    1 1105]]
Epoch: [70/200], cls_loss: 0.0132, transfer_loss: 0.0121, total_Loss: 0.0193, test_loss 4.086025
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3927 1167 2985  179]
 [ 717  790  332  502]
 [ 863  427  328  283]
 [   0    1    0 1108]]
Epoch: [71/200], cls_loss: 0.0275, transfer_loss: 0.0111, total_Loss: 0.0330, test_loss 4.311296
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[4239 1484 2428  107]
 [ 794  986  171  390]
 [ 976  622  124  179]
 [   1    2    0 1106]]
Epoch: [72/200], cls_loss: 0.0067, transfer_loss: 0.0097, total_Loss: 0.0115, test_loss 3.791743
trian begin
trian end
n_person 322
SAMPLE
BEST_F1_MI: 0.533103093541039 BEST_F1_MA: 0.5291639888893159
[[3474 1675 3034   75]
 [ 888  835  254  364]
 [ 948  514  243  196]
 [   1    1    0 1107]]
Epoch: [73/200], cls_loss: 0.0094, transfer_loss: 0.0088, total_Loss: 0.0138, test_loss 4.788745
[[3497 2540 2037  184]
 [ 266 1273  561  241]
 [ 433  713  619  136]
 [   0    3    3 1103]]
[[5291 1068 1784  115]
 [1166  691  249  235]
 [1160  434  171  136]
 [   0    6    1 1102]]
ARG: Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, max_iter=20000, momentum=0.9, n_class=4, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='UCI', tgt_domain='WISDM', tname='transfer', transfer_loss='twommd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
CL_weight [1, 1, 1, 1]

nohup: ignoring input
twommd 2022 UCI WISDM DAN/DAN.yaml
Namespace(backbone='resnet50', batch_size=32, config='DAN/DAN.yaml', data_dir='data', device=device(type='cuda'), early_stop=50, epoch_based_training=False, lr=0.003, lr_decay=0.75, lr_gamma=0.0003, lr_scheduler=True, momentum=0.9, n_epoch=200, n_iter_per_epoch=100, num_workers=3, seed=2022, src_domain='UCI', tgt_domain='WISDM', tname='transfer', transfer_loss='twommd', transfer_loss_weight=0.5, use_bottleneck=True, weight_decay=0.0005)
JUST DO IT
run my Parkinson code
transfer
TRAIN Length: 3369 615 TEST Length: 13609 322
DATA_PROFILE   train: 3369 train2: 13609 test: 13609
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f7708a117c0> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f7700491130> True
DATASET.SHAPE: <data_loader.GetLoader object at 0x7f770063f340> False
CLASS: 4 322
LLL: {}
BOTTLENECK_LIST: [Linear(in_features=2048, out_features=256, bias=True), ReLU()]
TYPE: {'loss_type': 'twommd', 'max_iter': 20000, 'num_class': 4, 'my_person_item': <my_person_item.PersonItem object at 0x7f7700491b20>}
TransferNet(
  (base_network): ResNet(
    (conv1): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(64, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): Bottleneck(
        (conv1): Conv1d(256, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(64, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): Bottleneck(
        (conv1): Conv1d(256, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(64, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv1d(256, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(128, 128, kernel_size=(11,), stride=(2,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(128, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): Bottleneck(
        (conv1): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(128, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): Bottleneck(
        (conv1): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(128, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): Bottleneck(
        (conv1): Conv1d(512, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(128, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv1d(512, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(2,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(256, 1024, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): Bottleneck(
        (conv1): Conv1d(1024, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(256, 1024, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): Bottleneck(
        (conv1): Conv1d(1024, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(256, 1024, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (3): Bottleneck(
        (conv1): Conv1d(1024, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(256, 1024, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (4): Bottleneck(
        (conv1): Conv1d(1024, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(256, 1024, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (5): Bottleneck(
        (conv1): Conv1d(1024, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(256, 1024, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(512, 512, kernel_size=(11,), stride=(2,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(512, 2048, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,), bias=False)
          (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (1): Bottleneck(
        (conv1): Conv1d(2048, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(512, 2048, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
      (2): Bottleneck(
        (conv1): Conv1d(2048, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)
        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv1d(512, 2048, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
        (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.2, inplace=False)
      )
    )
    (avgpool): AdaptiveAvgPool1d(output_size=1)
  )
  (bottleneck_layer): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (classifier_layer): Linear(in_features=256, out_features=4, bias=True)
  (adapt_loss): TransferLoss(
    (loss_func): TWOMMDLoss()
  )
  (criterion): CrossEntropyLoss()
)
initial_lr 1.0
transfer_world
1.8.1+cu111
True
LEN: 0 0
LOADER: <data_loader.InfiniteDataLoader object at 0x7f7700491a60> <data_loader.InfiniteDataLoader object at 0x7f770051fd30>
N: 100
n_person 322
SAMPLE
F1_MI: 0.17201851715776326 F1_MA: 0.07338557993730407 ACC_MI: 0.17201851715776326 F1_MA: 0.043004629289440814
BEST_F1_MI: 0.17201851715776326 BEST_F1_MA: 0.07338557993730407 BEST_ACC_MI: 0.17201851715776326 BEST_F1_MA: 0.043004629289440814
[[   0 8258    0    0]
 [   0 2341    0    0]
 [   0 1901    0    0]
 [   0 1109    0    0]]
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.4751267543537365 F1_MA: 0.4229210238184201 ACC_MI: 0.4751267543537365 F1_MA: 0.3878772377789135
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.4229210238184201 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.3878772377789135
[[4729 1314 1699  516]
 [1536  419  280  106]
 [1374  278  214   35]
 [   5    0    0 1104]]
Epoch: [ 1/200], cls_loss: 1.1540, transfer_loss: 0.0002, total_Loss: 1.1541
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.276287750753178 F1_MA: 0.46942588511243943 ACC_MI: 0.276287750753178 F1_MA: 0.45580787009914053
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.46942588511243943 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.45580787009914053
[[ 834 3834 3589    1]
 [ 336 1200  756   49]
 [ 336  924  624   17]
 [   0    6    1 1102]]
Epoch: [ 2/200], cls_loss: 0.4025, transfer_loss: 0.0006, total_Loss: 0.4028
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.30751708428246016 F1_MA: 0.462925428121269 ACC_MI: 0.30751708428246016 F1_MA: 0.44300484188780337
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.46942588511243943 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.45580787009914053
[[1334 3912 3010    2]
 [ 549 1387  311   94]
 [ 481 1021  360   39]
 [   2    3    0 1104]]
Epoch: [ 3/200], cls_loss: 0.1329, transfer_loss: 0.0011, total_Loss: 0.1334
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.46116540524652805 F1_MA: 0.4379277341688133 ACC_MI: 0.46116540524652805 F1_MA: 0.39790212581657314
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.46942588511243943 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.45580787009914053
[[4230 1496 2345  187]
 [ 776  574  432  559]
 [ 895  386  365  255]
 [   2    0    0 1107]]
Epoch: [ 4/200], cls_loss: 0.1615, transfer_loss: 0.0015, total_Loss: 0.1622
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.3767359835403042 F1_MA: 0.49806774252097574 ACC_MI: 0.3767359835403042 F1_MA: 0.4925058469332101
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.49806774252097574 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.4925058469332101
[[2565  981 4707    5]
 [ 646  587  991  117]
 [ 610  367  871   53]
 [   1    1    3 1104]]
Epoch: [ 5/200], cls_loss: 0.0777, transfer_loss: 0.0016, total_Loss: 0.0785
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.44595488279814827 F1_MA: 0.4891700251234626 ACC_MI: 0.44595488279814827 F1_MA: 0.49382792759183974
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.49806774252097574 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[4019  585 3652    2]
 [1229  415  616   81]
 [1054  280  532   35]
 [   3    2    1 1103]]
Epoch: [ 6/200], cls_loss: 0.0323, transfer_loss: 0.0017, total_Loss: 0.0332
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.4050995664633698 F1_MA: 0.505638354442212 ACC_MI: 0.4050995664633698 F1_MA: 0.493505695676211
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.505638354442212 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[2755 1783 3717    3]
 [ 665 1267  315   94]
 [ 648  814  388   51]
 [   1    5    0 1103]]
Epoch: [ 7/200], cls_loss: 0.1086, transfer_loss: 0.0025, total_Loss: 0.1099
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.3385994562421927 F1_MA: 0.4926721621734561 ACC_MI: 0.3385994562421927 F1_MA: 0.47940274411667705
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.505638354442212 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[1772 1249 5210   27]
 [ 465  966  743  167]
 [ 454  607  763   77]
 [   0    1    1 1107]]
Epoch: [ 8/200], cls_loss: 0.0397, transfer_loss: 0.0036, total_Loss: 0.0415
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.3646116540524653 F1_MA: 0.4865408647108139 ACC_MI: 0.36461165405246526 F1_MA: 0.4702124132234067
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.505638354442212 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[2219 2386 3621   32]
 [ 362 1126  702  151]
 [ 583  729  510   79]
 [   0    2    0 1107]]
Epoch: [ 9/200], cls_loss: 0.0326, transfer_loss: 0.0043, total_Loss: 0.0347
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.3657873466088618 F1_MA: 0.48642326523860246 ACC_MI: 0.3657873466088618 F1_MA: 0.47989939139619253
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.505638354442212 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[2334 2820 3095    9]
 [ 639 1159  505   38]
 [ 652  841  384   24]
 [   1    7    0 1101]]
Epoch: [10/200], cls_loss: 0.0308, transfer_loss: 0.0024, total_Loss: 0.0320
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.21816444999632595 F1_MA: 0.2523311401849458 ACC_MI: 0.21816444999632595 F1_MA: 0.2658682492872416
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.505638354442212 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[1243 1578 5437    0]
 [ 500 1022  771   48]
 [ 476  711  696   18]
 [   0    5 1096    8]]
Epoch: [11/200], cls_loss: 0.0271, transfer_loss: 0.0018, total_Loss: 0.0280
trian begin
trian end
n_person 322
SAMPLE
F1_MI: 0.3279447424498494 F1_MA: 0.4562406655961664 ACC_MI: 0.3279447424498494 F1_MA: 0.44735525175775653
BEST_F1_MI: 0.4751267543537365 BEST_F1_MA: 0.505638354442212 BEST_ACC_MI: 0.4751267543537365 BEST_F1_MA: 0.49382792759183974
[[2098  672 5462   26]
 [ 758  519  841  223]
 [ 719  338  741  103]
 [   0    2    2 1105]]
Epoch: [12/200], cls_loss: 0.0308, transfer_loss: 0.0026, total_Loss: 0.0321
trian begin
trian end
n_person 322
